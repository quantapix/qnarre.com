<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A quick narrative analyzer for &lsquo;bipolar&rsquo; text"><meta name=author content="Qnarre - Software is our passion"><meta name=generator content="Hugo 0.101.0"><meta name=docsearch:language content="en"><meta name=docsearch:version content="0.1.0"><title>Ragged Tensors For Text Processing Â· Qnarre</title><link rel=canonical href=https://quantapix.github.io/tech/ragged/><link href=../../css/bootstrap.min.css rel=stylesheet><link href=../../css/style.css rel=stylesheet><link rel=apple-touch-icon href=../../img/favs/apple-touch-icon.png sizes=180x180><link rel=icon href=../../img/favs/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=../../img/favs/favicon-16x16.png sizes=16x16 type=image/png><link rel=manifest href=../../img/favs/manifest.json><link rel=mask-icon href=../../img/favs/safari-pinned-tab color=#7952b3><link rel=icon href=../../img/favs/favicon.ico><meta name=theme-color content="#7952b3"></head><body><div class="skippy visually-hidden-focusable overflow-hidden"><div class=container-xl><a class="d-inline-flex p-2 m-1" href=#content>Skip to content</a></div></div><header class="navbar navbar-expand-md navbar-dark qal-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-2" href=../../><svg xmlns="http://www.w3.org/2000/svg" width="40" height="32" class="d-block my-1" viewBox="0 0 118 94" role="img"><title>Silcrow</title><path d="m67.476567 58.848956q2.916668 2.114585 4.375002 4.812503t1.458334 5.942711q0 5.250002-4.520836 8.421879-4.520835 3.208335-10.60938 3.208335-5.541669.0-9.406254-2.552085-3.864586-2.552084-3.864586-6.270836.0-2.151043 1.421876-3.500002 1.421876-1.3125 3.208335-1.3125 1.932293.0 3.026043 1.09375 1.093751 1.130209 1.786459 3.609377.911459 3.09896 2.296876 3.97396 1.385418.911459 3.208335.911459 2.187501.0 3.75521-1.239584t1.567709-3.026043q0-1.458334-1.020833-3.135418-1.057293-1.640626-6.708337-5.468753-6.526045-4.375002-9.369796-6.781253-2.843751-2.44271-4.375002-5.322919-1.531251-2.916669-1.531251-6.19792.0-3.09896 1.348959-5.432294 1.385417-2.333335 3.208335-3.427085 1.822918-1.130209 4.302085-1.713543-3.098959-2.260418-4.666668-4.921877-1.56771-2.66146-1.56771-5.76042.0-5.322919 4.484378-8.640629 4.484377-3.354168 10.901046-3.354168 5.395836.0 9.333338 2.515626t3.937502 6.088545q0 2.114584-1.494792 3.463543-1.494793 1.348959-3.427085 1.348959-1.895834.0-2.843752-.984375-.947917-1.020834-1.859376-3.718752-.838542-2.552085-2.078125-3.609377-1.239584-1.057292-3.463544-1.057292-2.296876.0-3.937502 1.276042-1.604167 1.276043-1.604167 3.062502.0 2.041667 1.567709 3.682293 1.531251 1.640626 7.473962 5.432294 5.578128 3.572919 8.239587 5.76042 2.697918 2.151043 4.229169 5.140627 1.567709 2.989585 1.567709 6.453128.0 4.411461-2.078126 7.218754-2.078126 2.807293-6.270836 4.010418zm1.166667-7.000003q0-3.682293-6.234378-8.531254-6.19792-4.885419-9.187505-4.885419-1.385417.0-2.661459 1.09375-1.239584 1.057293-1.239584 2.515627.0 3.463543 6.307295 8.421879 6.343753 4.958335 9.260421 4.958335 1.53125.0 2.625001-1.057292 1.130209-1.057292 1.130209-2.515626z" fill="#fff"/></svg></a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#qalNavbar aria-controls=qalNavbar aria-expanded=false aria-label="Toggle navigation"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" class="bi" fill="currentcolor" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M2.5 11.5A.5.5.0 013 11h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5zm0-4A.5.5.0 013 7h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5zm0-4A.5.5.0 013 3h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5z"/></svg></button><div class="collapse navbar-collapse" id=qalNavbar><hr class="d-md-none text-white-50"><ul class="navbar-nav flex-row flex-wrap qal-navbar-nav"><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../>Qnarre</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../modeling/>Modeling</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../semantics/>Semantics</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../analytics/>Analytics</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../reports/>Reports</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../story/>The Story</a></li></ul><hr class="d-md-none text-white-50"><ul class="navbar-nav flex-row flex-wrap ms-md-auto"><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=https://twitter.com/ikifor target=_blank rel=noopener><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" class="navbar-nav-svg d-inline-block align-text-top" viewBox="0 0 512 416.32" role="img"><title>Twitter</title><path fill="currentcolor" d="M160.83 416.32c193.2.0 298.92-160.22 298.92-298.92.0-4.51.0-9-.2-13.52A214 214 0 00512 49.38a212.93 212.93.0 01-60.44 16.6 105.7 105.7.0 0046.3-58.19 209 209 0 01-66.79 25.37 105.09 105.09.0 00-181.73 71.91 116.12 116.12.0 002.66 24c-87.28-4.3-164.73-46.3-216.56-109.82A105.48 105.48.0 0068 159.6a106.27 106.27.0 01-47.53-13.11v1.43a105.28 105.28.0 0084.21 103.06 105.67 105.67.0 01-47.33 1.84 105.06 105.06.0 0098.14 72.94A210.72 210.72.0 0125 370.84a202.17 202.17.0 01-25-1.43 298.85 298.85.0 00160.83 46.92"/></svg><small class="d-md-none ms-2">Twitter</small></a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=https://github.com/quantapix target=_blank rel=noopener><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" class="navbar-nav-svg d-inline-block align-text-top" viewBox="0 0 512 499.36" role="img"><title>GitHub</title><path fill="currentcolor" fill-rule="evenodd" d="M256 0C114.64.0.0 114.61.0 256c0 113.09 73.34 209 175.08 242.9 12.8 2.35 17.47-5.56 17.47-12.34.0-6.08-.22-22.18-.35-43.54-71.2 15.49-86.2-34.34-86.2-34.34-11.64-29.57-28.42-37.45-28.42-37.45-23.27-15.84 1.73-15.55 1.73-15.55 25.69 1.81 39.21 26.38 39.21 26.38 22.84 39.12 59.92 27.82 74.5 21.27 2.33-16.54 8.94-27.82 16.25-34.22-56.84-6.43-116.6-28.43-116.6-126.49.0-27.95 10-50.8 26.35-68.69-2.63-6.48-11.42-32.5 2.51-67.75.0.0 21.49-6.88 70.4 26.24a242.65 242.65.0 01128.18.0c48.87-33.13 70.33-26.24 70.33-26.24 14 35.25 5.18 61.27 2.55 67.75 16.41 17.9 26.31 40.75 26.31 68.69.0 98.35-59.85 120-116.88 126.32 9.19 7.9 17.38 23.53 17.38 47.41.0 34.22-.31 61.83-.31 70.23.0 6.85 4.61 14.81 17.6 12.31C438.72 464.97 512 369.08 512 256.02 512 114.62 397.37.0 256 0z"/></svg><small class="d-md-none ms-2">GitHub</small></a></li></ul><a class="btn btn-qal-download d-lg-inline-block my-2 my-md-0 ms-md-3" href=https://femfas.net/>femfas.net</a></div></nav></header><div class="container-xxl my-md-4 qal-layout"><aside class=qal-sidebar><nav class="collapse qal-links" id=qal-docs-nav aria-label="Nav links"><ul class="list-unstyled mb-0 py-3 pt-md-1"><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#modeling-collapse aria-expanded=false>
Modeling</button><div class=collapse id=modeling-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../modeling/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../modeling/simulation class="d-inline-flex align-items-center rounded">Judicial Simulation</a></li><li><a href=../../modeling/concepts class="d-inline-flex align-items-center rounded">Conceptual Model</a></li><li><a href=../../modeling/report class="d-inline-flex align-items-center rounded">Sample Report</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#semantics-collapse aria-expanded=false>
Semantics</button><div class=collapse id=semantics-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../semantics/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../semantics/simulation class="d-inline-flex align-items-center rounded">Judicial Simulation</a></li><li><a href=../../semantics/concepts class="d-inline-flex align-items-center rounded">Conceptual Model</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#analytics-collapse aria-expanded=false>
Analytics</button><div class=collapse id=analytics-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../analytics/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../analytics/prepare class="d-inline-flex align-items-center rounded">Preparing Documents</a></li><li><a href=../../analytics/extract class="d-inline-flex align-items-center rounded">Extracting Narratives</a></li><li><a href=../../analytics/output class="d-inline-flex align-items-center rounded">Standardized Output</a></li><li><a href=../../analytics/graph class="d-inline-flex align-items-center rounded">Conflict Graph</a></li><li><a href=../../analytics/analyze class="d-inline-flex align-items-center rounded">Irrefutable Analytics</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#reports-collapse aria-expanded=false>
Reports</button><div class=collapse id=reports-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../reports/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../reports/prepare class="d-inline-flex align-items-center rounded">Generating Reports</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#story-collapse aria-expanded=false>
The Story</button><div class=collapse id=story-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../story/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../story/about class="d-inline-flex align-items-center rounded">About</a></li><li><a href=../../story/blog class="d-inline-flex align-items-center rounded">Blog</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded" data-bs-toggle=collapse data-bs-target=#tech-collapse aria-expanded=true aria-current=true>
Available Tech</button><div class="collapse show" id=tech-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../tech/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../tech/trackable class="d-inline-flex align-items-center rounded">Trackable Persistence</a></li><li><a href=../../tech/gpus class="d-inline-flex align-items-center rounded">Many Smaller GPUs</a></li><li><a href=../../tech/dataset class="d-inline-flex align-items-center rounded">Datasets</a></li><li><a href=../../tech/masking class="d-inline-flex align-items-center rounded">Unified Masking</a></li><li><a href=../../tech/ragged class="d-inline-flex align-items-center rounded active" aria-current=page>Ragged Tensors</a></li><li><a href=../../tech/layers class="d-inline-flex align-items-center rounded">Layers Simplified</a></li><li><a href=../../tech/custom class="d-inline-flex align-items-center rounded">Custom Layers</a></li><li><a href=../../tech/autograph class="d-inline-flex align-items-center rounded">Autograph</a></li><li><a href=../../tech/metrics class="d-inline-flex align-items-center rounded">Modular Metrics</a></li><li><a href=../../tech/callbacks class="d-inline-flex align-items-center rounded">Extended Callbacks</a></li></ul></div></li></ul></nav></aside><main class="qal-main order-1"><div class="qal-intro ps-lg-4"><div class="d-md-flex flex-md-row align-items-center justify-content-between"><h1 class=qal-title id=content>Ragged Tensors For Text Processing</h1></div><p class=qal-lead></p></div><div class="qal-toc mt-4 mb-5 my-md-0 ps-xl-3 mb-lg-5 text-muted"><strong class="d-block h6 my-2 pb-2 border-bottom">On this page</strong><nav id=TableOfContents><ul><li><a href=#keras-workaround>Keras workaround</a></li><li><a href=#embedding-layer>Embedding layer</a></li><li><a href=#ragged-attention-mechanism>&ldquo;Ragged&rdquo; attention mechanism</a></li><li><a href=#training-session>Training session</a></li><li><a href=#eager-execution-mode>Eager execution mode</a></li></ul></nav></div><div class="qal-content ps-lg-4"><p><code>RaggedTensor</code>s are a newly added feature in TF. They intend to cleanly and efficiently solve the previously mentioned &ldquo;uneven sequence-length&rdquo; problem.</p><p>While easily convertible, they are different from the more general <code>SparseTensor</code>s, as they only allow &ldquo;ragged edges&rdquo;.</p><p>From an implementation point of view, <code>RaggedTensors</code> are efficiently represented as <code>composite tensor</code>s consisting of 1) a packed sequence of values and 2) a list of indices (effectively &ldquo;row lengths&rdquo;).</p><p>These new composite tensors are purpose-fitted to our sample text processing problem.</p><p>One significant advantage of their specific design is the fluid nature of their &ldquo;duality&rdquo;. On one hand, they can be viewed just as a simple vector of values, for efficient graph ops. On the other hand, they can be used as handy &ldquo;masks&rdquo;, to selectively extract just the right values from dense tensors.</p><p>To demonstrate their use, we set our objective to arrive at a model representable by the <a href=generated/images/tech/ragged.pdf>graph</a> and <a href=https://github.com/quantapix/qnarre/blob/master/docs/advanced_tf/ragged.ipynb>runnable example</a>.</p><p>Just as before, we need to prep our environment to run any meaningful code:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>dataset</span> <span class=k>as</span> <span class=nn>qd</span>
</span></span><span class=line><span class=cl><span class=n>ks</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span>
</span></span><span class=line><span class=cl><span class=n>kl</span> <span class=o>=</span> <span class=n>ks</span><span class=o>.</span><span class=n>layers</span>
</span></span></code></pre></div><p>Loading our already created meta data from the sources gives us:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>vocab</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>  <span class=o>(</span><span class=s1>&#39; &#39;</span>, <span class=s1>&#39;:&#39;</span>, <span class=s1>&#39;|&#39;</span>, <span class=s1>&#39;x&#39;</span>, <span class=s1>&#39;y&#39;</span>, <span class=s1>&#39;=&#39;</span>, <span class=s1>&#39;,&#39;</span>, <span class=s1>&#39;+&#39;</span>, <span class=s1>&#39;-&#39;</span>, <span class=s1>&#39;*&#39;</span>, <span class=s1>&#39;0&#39;</span>, <span class=s1>&#39;1&#39;</span>, <span class=s1>&#39;2&#39;</span>, <span class=s1>&#39;3&#39;</span>, <span class=s1>&#39;4&#39;</span>, <span class=s1>&#39;5&#39;</span>, <span class=s1>&#39;6&#39;</span>, <span class=s1>&#39;7&#39;</span>, <span class=s1>&#39;8&#39;</span>, <span class=s1>&#39;9&#39;</span><span class=o>)</span>
</span></span></code></pre></div><p>Our previously introduced <code>adapter</code> to our various datasets, themselves loadable from our stored samples, is adjusted slightly: we don&rsquo;t immediately convert the created ragged tensors to dense tensors anymore.</p><h2 id=keras-workaround>Keras workaround</h2><p>While Keras has the intention of supporting ragged input tensors (the <code>ragged=True</code> optional keyword argument is already available), passing in our <code>composite tensors</code> doesn&rsquo;t seem to work just yet. To work around this problem, we split our ragged tensors into its components, pass the components in and then reassemble them, once inside the model.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>adapter</span><span class=p>(</span><span class=n>d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;defs&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>ss</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>fill</span><span class=p>([</span><span class=n>ds</span><span class=o>.</span><span class=n>nrows</span><span class=p>(),</span> <span class=mi>1</span><span class=p>],</span> <span class=n>qd</span><span class=o>.</span><span class=n>SEP</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;op&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>ds</span><span class=p>,</span> <span class=n>ss</span><span class=p>,</span> <span class=n>os</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;res&#39;</span><span class=p>])[:,</span> <span class=p>:</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>flat_values</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>row_splits</span><span class=p>),</span> <span class=n>y</span>
</span></span></code></pre></div><p>With the adapter configured, our dataset streaming function is simple and looks as expected:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dset_for</span><span class=p>(</span><span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>TFRecordDataset</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>files</span><span class=p>(</span><span class=n>ps</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>batch</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;defs&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;op&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;res&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>parse_example</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>fs</span><span class=p>))</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>caster</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>adapter</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=embedding-layer>Embedding layer</h2><p>Just as in our previous blog, our elementary math training problem calls for first embedding the passed-in tokens into more spacious hidden dimensions.</p><p>Hence our already defined <code>Embed</code> class only needs to be adjusted to work with ragged tensor arguments. Specifically, after reassembling our <code>RaggedTensor</code> inputs from its passed-in components, we simply apply our trusty <code>embedding_lookup</code> to all the flattened or &ldquo;bunched-up&rdquo; tokens:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Embed</span><span class=p>(</span><span class=n>kl</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_vocab</span><span class=p>,</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;emb&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>fv</span><span class=p>,</span> <span class=n>rs</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_row_splits</span><span class=p>(</span><span class=n>fv</span><span class=p>,</span> <span class=n>rs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>ragged</span><span class=o>.</span><span class=n>map_flat_values</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>embedding_lookup</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>emb</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><h2 id=ragged-attention-mechanism>&ldquo;Ragged&rdquo; attention mechanism</h2><p>Our <code>Reflect</code> layer will need slightly more changes.</p><p>As the <code>flat_values</code> of our ragged inputs loose their batch dimensions, the matrix multiplications become simpler (expressed here through the favorite <code>einsum</code>, see <a href=https://rockt.github.io/2018/04/30/einsum>here</a>).</p><p>Since the <code>attention</code> mechanism&rsquo;s <code>q</code>, <code>k</code> and <code>v</code> components are element-wise tied to their inputs, the new &ldquo;raggedness&rdquo; of the inputs doesn&rsquo;t change their scope. This means that we only need to change the content of our <code>RaggedTensor</code>s, the &ldquo;row_lengths&rdquo; stay the same as implemented by the <code>with_values</code> method.</p><p>When we switch over to cross-products, for scoring our calculated attention coefficients, we need to use dense tensors once again. But the actual result of the layer is a <code>RaggedTensor</code>.</p><p>Since its &ldquo;raggedness&rdquo; is the same as the layer&rsquo;s input&rsquo;s raggedness, we can conveniently recreate the same shaped <code>RaggedTensor</code> from the respective values of the just calculated dense tensor by using the original ragged input&rsquo;s <code>row_lengths</code> method. Very convenient indeed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Reflect</span><span class=p>(</span><span class=n>kl</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>build</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>shape</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=n>s</span><span class=o>**</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;q&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>s</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>s</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;v&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>s</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=n>build</span><span class=p>(</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>with_values</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;ni,ij-&gt;nj&#39;</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>flat_values</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>q</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>with_values</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;ni,ij-&gt;nj&#39;</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>flat_values</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>k</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>with_values</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;ni,ij-&gt;nj&#39;</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>flat_values</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>v</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsi,bzi-&gt;bsz&#39;</span><span class=p>,</span> <span class=n>q</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>(),</span> <span class=n>k</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>y</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsz,bzi-&gt;bsi&#39;</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>v</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_tensor</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>lengths</span><span class=o>=</span><span class=n>x</span><span class=o>.</span><span class=n>row_lengths</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><p>We need to implement similar changes in our <code>Expand</code> layer.</p><p>&ldquo;Inflating&rdquo; our hidden dimensions, for the intrinsic learning purposes, requires a fixed width, hence we immediately convert to a larger dense tensor. However, as we are done with our &ldquo;ragged&rdquo; token calculations, we can simply pad the input to the layer to our expected <code>len_max_input</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Expand</span><span class=p>(</span><span class=n>kl</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ps</span> <span class=o>=</span> <span class=n>ps</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>shape</span><span class=p>(</span><span class=n>y</span><span class=p>)[</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=p>[[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>ps</span><span class=o>.</span><span class=n>len_max_input</span> <span class=o>-</span> <span class=n>s</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><h2 id=training-session>Training session</h2><p>We are ready now to define our model.</p><p>We have the two inputs, the two components of our input <code>RaggedTensor</code>. We also use our new <code>Embed</code>, <code>Reflect</code> and <code>Expand</code> layers adjusted to work with our sudden &ldquo;raggedness&rdquo;. The rest of the model is simply carried over from the previous blog:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>model_for</span><span class=p>(</span><span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int32&#39;</span><span class=p>),</span>  <span class=c1># , ragged=True)</span>
</span></span><span class=line><span class=cl>        <span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int64&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Embed</span><span class=p>(</span><span class=n>ps</span><span class=p>)(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Reflect</span><span class=p>()(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Expand</span><span class=p>(</span><span class=n>ps</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>kl</span><span class=o>.</span><span class=n>Reshape</span><span class=p>((</span><span class=n>ps</span><span class=o>.</span><span class=n>len_max_input</span> <span class=o>*</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span><span class=p>,</span> <span class=p>))(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>kl</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_dense</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>kl</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_vocab</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;dbd&#39;</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=kc>None</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span> <span class=o>=</span> <span class=n>ks</span><span class=o>.</span><span class=n>Model</span><span class=p>(</span><span class=n>inputs</span><span class=o>=</span><span class=n>x</span><span class=p>,</span> <span class=n>outputs</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>optimizer</span><span class=o>=</span><span class=n>ps</span><span class=o>.</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>loss</span><span class=o>=</span><span class=n>ps</span><span class=o>.</span><span class=n>loss</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=n>ps</span><span class=o>.</span><span class=n>metric</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>summary</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>m</span>
</span></span></code></pre></div><p>Our parameters are also unchanged:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_batch</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_dense</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_hidden</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_vocab</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>vocab</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>len_max_input</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>losses</span><span class=o>.</span><span class=n>SparseCategoricalCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>metric</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>SparseCategoricalCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>num_epochs</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_shards</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>Adam</span><span class=p>(),</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>By firing up our training session, we can confirm the model&rsquo;s layers and connections. Also, the listing of a short session follows.</p><p>We can easily adjust the parameters to tailor the length of the sessions to our objectives. However, at this point the results are still largely meaningless and extending the trainings is not yet warranted.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ps</span> <span class=o>=</span> <span class=n>qd</span><span class=o>.</span><span class=n>Params</span><span class=p>(</span><span class=o>**</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>masking</span> <span class=k>as</span> <span class=nn>qm</span>
</span></span><span class=line><span class=cl><span class=n>qm</span><span class=o>.</span><span class=n>main_graph</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>dset_for</span><span class=p>(</span><span class=n>ps</span><span class=p>),</span> <span class=n>model_for</span><span class=p>(</span><span class=n>ps</span><span class=p>))</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>  Model: <span class=s2>&#34;model&#34;</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  Layer <span class=o>(</span><span class=nb>type</span><span class=o>)</span>                    Output Shape         Param <span class=c1>#     Connected to</span>
</span></span><span class=line><span class=cl>  <span class=o>==================================================================================================</span>
</span></span><span class=line><span class=cl>  input_1 <span class=o>(</span>InputLayer<span class=o>)</span>            <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  input_2 <span class=o>(</span>InputLayer<span class=o>)</span>            <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  embed <span class=o>(</span>Embed<span class=o>)</span>                   <span class=o>(</span>None, None, 15<span class=o>)</span>     <span class=m>300</span>         input_1<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   input_2<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  reflect <span class=o>(</span>Reflect<span class=o>)</span>               <span class=o>(</span>None, None, 15<span class=o>)</span>     <span class=m>675</span>         embed<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  expand <span class=o>(</span>Expand<span class=o>)</span>                 <span class=o>(</span>None, None, 15<span class=o>)</span>     <span class=m>0</span>           reflect<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  reshape <span class=o>(</span>Reshape<span class=o>)</span>               <span class=o>(</span>None, 300<span class=o>)</span>          <span class=m>0</span>           expand<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  dense <span class=o>(</span>Dense<span class=o>)</span>                   <span class=o>(</span>None, 150<span class=o>)</span>          <span class=m>45150</span>       reshape<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  dbd <span class=o>(</span>Dense<span class=o>)</span>                     <span class=o>(</span>None, 20<span class=o>)</span>           <span class=m>3020</span>        dense<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  <span class=o>==================================================================================================</span>
</span></span><span class=line><span class=cl>  Total params: 49,145
</span></span><span class=line><span class=cl>  Trainable params: 49,145
</span></span><span class=line><span class=cl>  Non-trainable params: <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  None
</span></span><span class=line><span class=cl>  Epoch 1/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 7s 7ms/step - loss: 1.7148 - sparse_categorical_crossentropy: 1.7148
</span></span><span class=line><span class=cl>  Epoch 2/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.4729 - sparse_categorical_crossentropy: 1.4729
</span></span><span class=line><span class=cl>  Epoch 3/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.3973 - sparse_categorical_crossentropy: 1.3973
</span></span><span class=line><span class=cl>  Epoch 4/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.3517 - sparse_categorical_crossentropy: 1.3517
</span></span><span class=line><span class=cl>  Epoch 5/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.3136 - sparse_categorical_crossentropy: 1.3136
</span></span><span class=line><span class=cl>  Epoch 6/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.2838 - sparse_categorical_crossentropy: 1.2838
</span></span><span class=line><span class=cl>  Epoch 7/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.2500 - sparse_categorical_crossentropy: 1.2500
</span></span><span class=line><span class=cl>  Epoch 8/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.2134 - sparse_categorical_crossentropy: 1.2134
</span></span><span class=line><span class=cl>  Epoch 9/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.1745 - sparse_categorical_crossentropy: 1.1745
</span></span><span class=line><span class=cl>  Epoch 10/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 3s 3ms/step - loss: 1.1284 - sparse_categorical_crossentropy: 1.1284
</span></span></code></pre></div><p>With our TensorBoard <code>callback</code> in place, the model&rsquo;s <code>fit</code> method will generate the standard summaries that TB can conveniently visualize.</p><p>If you haven&rsquo;t run the code, an already generated graph is <a href=generated/images/tech/ragged.pdf>here</a>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>%</span><span class=n>load_ext</span> <span class=n>tensorboard</span>
</span></span><span class=line><span class=cl><span class=c1>#%tensorboard --logdir /tmp/q/logs</span>
</span></span></code></pre></div><h2 id=eager-execution-mode>Eager execution mode</h2><p>We can also switch over to the new <code>eager</code> execution mode. This is particularly convenient for experimentation, as all ops are immediately executed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>main_eager</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>ds</span><span class=p>,</span> <span class=n>m</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>step</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>GradientTape</span><span class=p>()</span> <span class=k>as</span> <span class=n>tape</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logits</span> <span class=o>=</span> <span class=n>m</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>ps</span><span class=o>.</span><span class=n>loss</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>logits</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>+=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>losses</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>xent</span> <span class=o>=</span> <span class=n>ps</span><span class=o>.</span><span class=n>metric</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>logits</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>grads</span> <span class=o>=</span> <span class=n>tape</span><span class=o>.</span><span class=n>gradient</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>m</span><span class=o>.</span><span class=n>trainable_variables</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ps</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>apply_gradients</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>grads</span><span class=p>,</span> <span class=n>m</span><span class=o>.</span><span class=n>trainable_variables</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>loss</span><span class=p>,</span> <span class=n>xent</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>epoch</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span><span class=p>,</span> <span class=n>loss</span><span class=p>,</span> <span class=n>xent</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span> <span class=ow>in</span> <span class=n>ds</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>s</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span><span class=p>,</span> <span class=n>xent</span> <span class=o>=</span> <span class=n>step</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>tf</span><span class=o>.</span><span class=n>equal</span><span class=p>(</span><span class=n>s</span> <span class=o>%</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>e</span> <span class=o>=</span> <span class=n>ps</span><span class=o>.</span><span class=n>metric</span><span class=o>.</span><span class=n>result</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>tf</span><span class=o>.</span><span class=n>print</span><span class=p>(</span><span class=s1>&#39;Step:&#39;</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=s1>&#39;, loss:&#39;</span><span class=p>,</span> <span class=n>loss</span><span class=p>,</span> <span class=s1>&#39;, xent:&#39;</span><span class=p>,</span> <span class=n>e</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>loss</span><span class=p>,</span> <span class=n>xent</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>e</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>num_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=p>,</span> <span class=n>xent</span> <span class=o>=</span> <span class=n>epoch</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Epoch </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s1> loss:&#39;</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>numpy</span><span class=p>(),</span> <span class=s1>&#39;, xent:&#39;</span><span class=p>,</span> <span class=n>xent</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span></code></pre></div><p>And here is a much shortened <code>eager</code> session:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ps</span><span class=o>.</span><span class=n>num_epochs</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>main_eager</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>dset_for</span><span class=p>(</span><span class=n>ps</span><span class=p>)</span><span class=o>.</span><span class=n>take</span><span class=p>(</span><span class=mi>100</span><span class=p>),</span> <span class=n>model_for</span><span class=p>(</span><span class=n>ps</span><span class=p>))</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>  Model: <span class=s2>&#34;model_2&#34;</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  Layer <span class=o>(</span><span class=nb>type</span><span class=o>)</span>                    Output Shape         Param <span class=c1>#     Connected to</span>
</span></span><span class=line><span class=cl>  <span class=o>==================================================================================================</span>
</span></span><span class=line><span class=cl>  input_5 <span class=o>(</span>InputLayer<span class=o>)</span>            <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  input_6 <span class=o>(</span>InputLayer<span class=o>)</span>            <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  embed_2 <span class=o>(</span>Embed<span class=o>)</span>                 <span class=o>(</span>None, None, 15<span class=o>)</span>     <span class=m>300</span>         input_5<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   input_6<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  reflect_2 <span class=o>(</span>Reflect<span class=o>)</span>             <span class=o>(</span>None, None, 15<span class=o>)</span>     <span class=m>675</span>         embed_2<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  expand_2 <span class=o>(</span>Expand<span class=o>)</span>               <span class=o>(</span>None, None, 15<span class=o>)</span>     <span class=m>0</span>           reflect_2<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  reshape_2 <span class=o>(</span>Reshape<span class=o>)</span>             <span class=o>(</span>None, 300<span class=o>)</span>          <span class=m>0</span>           expand_2<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  dense_2 <span class=o>(</span>Dense<span class=o>)</span>                 <span class=o>(</span>None, 150<span class=o>)</span>          <span class=m>45150</span>       reshape_2<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  dbd <span class=o>(</span>Dense<span class=o>)</span>                     <span class=o>(</span>None, 20<span class=o>)</span>           <span class=m>3020</span>        dense_2<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  <span class=o>==================================================================================================</span>
</span></span><span class=line><span class=cl>  Total params: 49,145
</span></span><span class=line><span class=cl>  Trainable params: 49,145
</span></span><span class=line><span class=cl>  Non-trainable params: <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  None
</span></span><span class=line><span class=cl>  Step: <span class=m>10</span> , loss: 2.32437706 , xent: 1.38269854
</span></span><span class=line><span class=cl>  Step: <span class=m>20</span> , loss: 4.57577085 , xent: 1.38721442
</span></span><span class=line><span class=cl>  Step: <span class=m>30</span> , loss: 1.85324097 , xent: 1.39087987
</span></span><span class=line><span class=cl>  Step: <span class=m>40</span> , loss: 3.42399216 , xent: 1.39260852
</span></span><span class=line><span class=cl>  Step: <span class=m>50</span> , loss: 2.88146091 , xent: 1.3952688
</span></span><span class=line><span class=cl>  Step: <span class=m>60</span> , loss: 1.36529291 , xent: 1.39925313
</span></span><span class=line><span class=cl>  Step: <span class=m>70</span> , loss: 2.36236858 , xent: 1.40269136
</span></span><span class=line><span class=cl>  Step: <span class=m>80</span> , loss: 1.86278176 , xent: 1.40463638
</span></span><span class=line><span class=cl>  Step: <span class=m>90</span> , loss: 3.87270284 , xent: 1.40630019
</span></span><span class=line><span class=cl>  Step: <span class=m>100</span> , loss: 2.69483709 , xent: 1.40788627
</span></span><span class=line><span class=cl>  Epoch <span class=m>0</span> loss: 2.694837 , xent: 1.4078863
</span></span></code></pre></div><p>This concludes our blog, please see how to avoid &ldquo;layer-proliferation&rdquo; complexity by clicking on the next blog.</p></div></main></div><footer class="qal-footer py-5 bg-light"><div class=container><div class=row><div class=col-lg><a class=d-inline-flex href=../../><svg xmlns="http://www.w3.org/2000/svg" width="40" height="32" class="d-block me-2" viewBox="0 0 118 94" role="img"><title>Silcrow</title><path d="m67.476567 58.848956q2.916668 2.114585 4.375002 4.812503t1.458334 5.942711q0 5.250002-4.520836 8.421879-4.520835 3.208335-10.60938 3.208335-5.541669.0-9.406254-2.552085-3.864586-2.552084-3.864586-6.270836.0-2.151043 1.421876-3.500002 1.421876-1.3125 3.208335-1.3125 1.932293.0 3.026043 1.09375 1.093751 1.130209 1.786459 3.609377.911459 3.09896 2.296876 3.97396 1.385418.911459 3.208335.911459 2.187501.0 3.75521-1.239584t1.567709-3.026043q0-1.458334-1.020833-3.135418-1.057293-1.640626-6.708337-5.468753-6.526045-4.375002-9.369796-6.781253-2.843751-2.44271-4.375002-5.322919-1.531251-2.916669-1.531251-6.19792.0-3.09896 1.348959-5.432294 1.385417-2.333335 3.208335-3.427085 1.822918-1.130209 4.302085-1.713543-3.098959-2.260418-4.666668-4.921877-1.56771-2.66146-1.56771-5.76042.0-5.322919 4.484378-8.640629 4.484377-3.354168 10.901046-3.354168 5.395836.0 9.333338 2.515626t3.937502 6.088545q0 2.114584-1.494792 3.463543-1.494793 1.348959-3.427085 1.348959-1.895834.0-2.843752-.984375-.947917-1.020834-1.859376-3.718752-.838542-2.552085-2.078125-3.609377-1.239584-1.057292-3.463544-1.057292-2.296876.0-3.937502 1.276042-1.604167 1.276043-1.604167 3.062502.0 2.041667 1.567709 3.682293 1.531251 1.640626 7.473962 5.432294 5.578128 3.572919 8.239587 5.76042 2.697918 2.151043 4.229169 5.140627 1.567709 2.989585 1.567709 6.453128.0 4.411461-2.078126 7.218754-2.078126 2.807293-6.270836 4.010418zm1.166667-7.000003q0-3.682293-6.234378-8.531254-6.19792-4.885419-9.187505-4.885419-1.385417.0-2.661459 1.09375-1.239584 1.057293-1.239584 2.515627.0 3.463543 6.307295 8.421879 6.343753 4.958335 9.260421 4.958335 1.53125.0 2.625001-1.057292 1.130209-1.057292 1.130209-2.515626z" fill="#0"/></svg><span class=fs-5>&copy; 2022 Qnarre</span></a><ul class="list-unstyled small text-muted"><li class=mb-2>Software is our passion.</li></ul></div></div></div></footer><script src=../../js/bootstrap.bundle.min.js></script>
<script src=../../js/script.min.js></script></body></html>
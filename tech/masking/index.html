<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A quick narrative analyzer for &lsquo;bipolar&rsquo; text"><meta name=author content="Qnarre - Software is our passion"><meta name=generator content="Hugo 0.101.0"><meta name=docsearch:language content="en"><meta name=docsearch:version content="0.1.0"><title>Unified Adaptable Masking That Follows · Qnarre</title><link rel=canonical href=https://quantapix.github.io/tech/masking/><link href=../../css/bootstrap.min.css rel=stylesheet><link href=../../css/style.css rel=stylesheet><link rel=apple-touch-icon href=../../img/favs/apple-touch-icon.png sizes=180x180><link rel=icon href=../../img/favs/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=../../img/favs/favicon-16x16.png sizes=16x16 type=image/png><link rel=manifest href=../../img/favs/manifest.json><link rel=mask-icon href=../../img/favs/safari-pinned-tab color=#7952b3><link rel=icon href=../../img/favs/favicon.ico><meta name=theme-color content="#7952b3"></head><body><div class="skippy visually-hidden-focusable overflow-hidden"><div class=container-xl><a class="d-inline-flex p-2 m-1" href=#content>Skip to content</a></div></div><header class="navbar navbar-expand-md navbar-dark qal-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-2" href=../../><svg xmlns="http://www.w3.org/2000/svg" width="40" height="32" class="d-block my-1" viewBox="0 0 118 94" role="img"><title>Silcrow</title><path d="m67.476567 58.848956q2.916668 2.114585 4.375002 4.812503t1.458334 5.942711q0 5.250002-4.520836 8.421879-4.520835 3.208335-10.60938 3.208335-5.541669.0-9.406254-2.552085-3.864586-2.552084-3.864586-6.270836.0-2.151043 1.421876-3.500002 1.421876-1.3125 3.208335-1.3125 1.932293.0 3.026043 1.09375 1.093751 1.130209 1.786459 3.609377.911459 3.09896 2.296876 3.97396 1.385418.911459 3.208335.911459 2.187501.0 3.75521-1.239584t1.567709-3.026043q0-1.458334-1.020833-3.135418-1.057293-1.640626-6.708337-5.468753-6.526045-4.375002-9.369796-6.781253-2.843751-2.44271-4.375002-5.322919-1.531251-2.916669-1.531251-6.19792.0-3.09896 1.348959-5.432294 1.385417-2.333335 3.208335-3.427085 1.822918-1.130209 4.302085-1.713543-3.098959-2.260418-4.666668-4.921877-1.56771-2.66146-1.56771-5.76042.0-5.322919 4.484378-8.640629 4.484377-3.354168 10.901046-3.354168 5.395836.0 9.333338 2.515626t3.937502 6.088545q0 2.114584-1.494792 3.463543-1.494793 1.348959-3.427085 1.348959-1.895834.0-2.843752-.984375-.947917-1.020834-1.859376-3.718752-.838542-2.552085-2.078125-3.609377-1.239584-1.057292-3.463544-1.057292-2.296876.0-3.937502 1.276042-1.604167 1.276043-1.604167 3.062502.0 2.041667 1.567709 3.682293 1.531251 1.640626 7.473962 5.432294 5.578128 3.572919 8.239587 5.76042 2.697918 2.151043 4.229169 5.140627 1.567709 2.989585 1.567709 6.453128.0 4.411461-2.078126 7.218754-2.078126 2.807293-6.270836 4.010418zm1.166667-7.000003q0-3.682293-6.234378-8.531254-6.19792-4.885419-9.187505-4.885419-1.385417.0-2.661459 1.09375-1.239584 1.057293-1.239584 2.515627.0 3.463543 6.307295 8.421879 6.343753 4.958335 9.260421 4.958335 1.53125.0 2.625001-1.057292 1.130209-1.057292 1.130209-2.515626z" fill="#fff"/></svg></a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#qalNavbar aria-controls=qalNavbar aria-expanded=false aria-label="Toggle navigation"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" class="bi" fill="currentcolor" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M2.5 11.5A.5.5.0 013 11h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5zm0-4A.5.5.0 013 7h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5zm0-4A.5.5.0 013 3h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5z"/></svg></button><div class="collapse navbar-collapse" id=qalNavbar><hr class="d-md-none text-white-50"><ul class="navbar-nav flex-row flex-wrap qal-navbar-nav"><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../>Qnarre</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../modeling/>Modeling</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../semantics/>Semantics</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../analytics/>Analytics</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../reports/>Reports</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../story/>The Story</a></li></ul><hr class="d-md-none text-white-50"><ul class="navbar-nav flex-row flex-wrap ms-md-auto"><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=https://twitter.com/ikifor target=_blank rel=noopener><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" class="navbar-nav-svg d-inline-block align-text-top" viewBox="0 0 512 416.32" role="img"><title>Twitter</title><path fill="currentcolor" d="M160.83 416.32c193.2.0 298.92-160.22 298.92-298.92.0-4.51.0-9-.2-13.52A214 214 0 00512 49.38a212.93 212.93.0 01-60.44 16.6 105.7 105.7.0 0046.3-58.19 209 209 0 01-66.79 25.37 105.09 105.09.0 00-181.73 71.91 116.12 116.12.0 002.66 24c-87.28-4.3-164.73-46.3-216.56-109.82A105.48 105.48.0 0068 159.6a106.27 106.27.0 01-47.53-13.11v1.43a105.28 105.28.0 0084.21 103.06 105.67 105.67.0 01-47.33 1.84 105.06 105.06.0 0098.14 72.94A210.72 210.72.0 0125 370.84a202.17 202.17.0 01-25-1.43 298.85 298.85.0 00160.83 46.92"/></svg><small class="d-md-none ms-2">Twitter</small></a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=https://github.com/quantapix target=_blank rel=noopener><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" class="navbar-nav-svg d-inline-block align-text-top" viewBox="0 0 512 499.36" role="img"><title>GitHub</title><path fill="currentcolor" fill-rule="evenodd" d="M256 0C114.64.0.0 114.61.0 256c0 113.09 73.34 209 175.08 242.9 12.8 2.35 17.47-5.56 17.47-12.34.0-6.08-.22-22.18-.35-43.54-71.2 15.49-86.2-34.34-86.2-34.34-11.64-29.57-28.42-37.45-28.42-37.45-23.27-15.84 1.73-15.55 1.73-15.55 25.69 1.81 39.21 26.38 39.21 26.38 22.84 39.12 59.92 27.82 74.5 21.27 2.33-16.54 8.94-27.82 16.25-34.22-56.84-6.43-116.6-28.43-116.6-126.49.0-27.95 10-50.8 26.35-68.69-2.63-6.48-11.42-32.5 2.51-67.75.0.0 21.49-6.88 70.4 26.24a242.65 242.65.0 01128.18.0c48.87-33.13 70.33-26.24 70.33-26.24 14 35.25 5.18 61.27 2.55 67.75 16.41 17.9 26.31 40.75 26.31 68.69.0 98.35-59.85 120-116.88 126.32 9.19 7.9 17.38 23.53 17.38 47.41.0 34.22-.31 61.83-.31 70.23.0 6.85 4.61 14.81 17.6 12.31C438.72 464.97 512 369.08 512 256.02 512 114.62 397.37.0 256 0z"/></svg><small class="d-md-none ms-2">GitHub</small></a></li></ul><a class="btn btn-qal-download d-lg-inline-block my-2 my-md-0 ms-md-3" href=../../simlaw/>SimLaw.app</a></div></nav></header><div class="container-xxl my-md-4 qal-layout"><aside class=qal-sidebar><nav class="collapse qal-links" id=qal-docs-nav aria-label="Nav links"><ul class="list-unstyled mb-0 py-3 pt-md-1"><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#modeling-collapse aria-expanded=false>
Modeling</button><div class=collapse id=modeling-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../modeling/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../modeling/simulation class="d-inline-flex align-items-center rounded">Judicial Simulation</a></li><li><a href=../../modeling/concepts class="d-inline-flex align-items-center rounded">Conceptual Model</a></li><li><a href=../../modeling/report class="d-inline-flex align-items-center rounded">Sample Report</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#semantics-collapse aria-expanded=false>
Semantics</button><div class=collapse id=semantics-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../semantics/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../semantics/simulation class="d-inline-flex align-items-center rounded">Judicial Simulation</a></li><li><a href=../../semantics/concepts class="d-inline-flex align-items-center rounded">Conceptual Model</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#analytics-collapse aria-expanded=false>
Analytics</button><div class=collapse id=analytics-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../analytics/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../analytics/prepare class="d-inline-flex align-items-center rounded">Preparing Documents</a></li><li><a href=../../analytics/extract class="d-inline-flex align-items-center rounded">Extracting Narratives</a></li><li><a href=../../analytics/output class="d-inline-flex align-items-center rounded">Standardized Output</a></li><li><a href=../../analytics/graph class="d-inline-flex align-items-center rounded">Conflict Graph</a></li><li><a href=../../analytics/analyze class="d-inline-flex align-items-center rounded">Irrefutable Analytics</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#reports-collapse aria-expanded=false>
Reports</button><div class=collapse id=reports-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../reports/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../reports/prepare class="d-inline-flex align-items-center rounded">Generating Reports</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#story-collapse aria-expanded=false>
The Story</button><div class=collapse id=story-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../story/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../story/about class="d-inline-flex align-items-center rounded">About</a></li><li><a href=../../story/blog class="d-inline-flex align-items-center rounded">Blog</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded" data-bs-toggle=collapse data-bs-target=#tech-collapse aria-expanded=true aria-current=true>
Available Tech</button><div class="collapse show" id=tech-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../tech/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../tech/trackable class="d-inline-flex align-items-center rounded">Trackable Persistence</a></li><li><a href=../../tech/gpus class="d-inline-flex align-items-center rounded">Many Smaller GPUs</a></li><li><a href=../../tech/dataset class="d-inline-flex align-items-center rounded">Datasets</a></li><li><a href=../../tech/masking class="d-inline-flex align-items-center rounded active" aria-current=page>Unified Masking</a></li><li><a href=../../tech/ragged class="d-inline-flex align-items-center rounded">Ragged Tensors</a></li><li><a href=../../tech/layers class="d-inline-flex align-items-center rounded">Layers Simplified</a></li><li><a href=../../tech/custom class="d-inline-flex align-items-center rounded">Custom Layers</a></li><li><a href=../../tech/autograph class="d-inline-flex align-items-center rounded">Autograph</a></li><li><a href=../../tech/metrics class="d-inline-flex align-items-center rounded">Modular Metrics</a></li><li><a href=../../tech/callbacks class="d-inline-flex align-items-center rounded">Extended Callbacks</a></li></ul></div></li></ul></nav></aside><main class="qal-main order-1"><div class="qal-intro ps-lg-4"><div class="d-md-flex flex-md-row align-items-center justify-content-between"><h1 class=qal-title id=content>Unified Adaptable Masking That Follows</h1></div><p class=qal-lead></p></div><div class="qal-toc mt-4 mb-5 my-md-0 ps-xl-3 mb-lg-5 text-muted"><strong class="d-block h6 my-2 pb-2 border-bottom">On this page</strong><nav id=TableOfContents><ul><li><a href=#prepare-the-datasets>Prepare the datasets</a></li><li><a href=#keras-masking-support>Keras masking support</a></li><li><a href=#attention-mechanism-with-masking>Attention mechanism with masking</a></li><li><a href=#training-session>Training session</a></li></ul></nav></div><div class="qal-content ps-lg-4"><p>A significant difference between image vs. text processing in machine learning is even vs. uneven input sequence length. Padding uneven textual input to a uniform length is an obvious, natural solution.</p><p>Indiscriminate padding can, however, pollute our calculations and introduce unwanted biases. Sometimes it is best to cleanly “mask-out” the padded input with carefully chosen, bias minimizing values.</p><p>Repeated, explicit and contextual masking calculations become necessary as a result. Historically such code has been cluttering the otherwise clean &ldquo;flow of data&rdquo;. Keras’ transparent masking mechanism allows for on-demand custom maskings.</p><p>Our objective here is to arrive at a model representable by the <a href=generated/images/tech/masking.pdf>graph</a> and <a href=https://github.com/quantapix/qnarre/blob/master/docs/advanced_tf/masking.ipynb>runnable example</a>.</p><p>Just as before, we need to prep our environment to run any meaningful code:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datetime</span> <span class=kn>import</span> <span class=n>datetime</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>dataset</span> <span class=k>as</span> <span class=nn>qd</span>
</span></span><span class=line><span class=cl><span class=n>ks</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span>
</span></span><span class=line><span class=cl><span class=n>kl</span> <span class=o>=</span> <span class=n>ks</span><span class=o>.</span><span class=n>layers</span>
</span></span></code></pre></div><p>Loading our already created meta data from the sources gives us:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>vocab</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>tokens</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>(</span><span class=s1>&#39; &#39;</span>, <span class=s1>&#39;:&#39;</span>, <span class=s1>&#39;|&#39;</span>, <span class=s1>&#39;x&#39;</span>, <span class=s1>&#39;y&#39;</span>, <span class=s1>&#39;=&#39;</span>, <span class=s1>&#39;,&#39;</span>, <span class=s1>&#39;+&#39;</span>, <span class=s1>&#39;-&#39;</span>, <span class=s1>&#39;*&#39;</span>, <span class=s1>&#39;0&#39;</span>, <span class=s1>&#39;1&#39;</span>, <span class=s1>&#39;2&#39;</span>, <span class=s1>&#39;3&#39;</span>, <span class=s1>&#39;4&#39;</span>, <span class=s1>&#39;5&#39;</span>, <span class=s1>&#39;6&#39;</span>, <span class=s1>&#39;7&#39;</span>, <span class=s1>&#39;8&#39;</span>, <span class=s1>&#39;9&#39;</span><span class=o>)</span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39; &#39;</span>: 0, <span class=s1>&#39;:&#39;</span>: 1, <span class=s1>&#39;|&#39;</span>: 2, <span class=s1>&#39;x&#39;</span>: 3, <span class=s1>&#39;y&#39;</span>: 4, <span class=s1>&#39;=&#39;</span>: 5, <span class=s1>&#39;,&#39;</span>: 6, <span class=s1>&#39;+&#39;</span>: 7, <span class=s1>&#39;-&#39;</span>: 8, <span class=s1>&#39;*&#39;</span>: 9, <span class=s1>&#39;0&#39;</span>: 10, <span class=s1>&#39;1&#39;</span>: 11, <span class=s1>&#39;2&#39;</span>: 12, <span class=s1>&#39;3&#39;</span>: 13, <span class=s1>&#39;4&#39;</span>: 14, <span class=s1>&#39;5&#39;</span>: 15, <span class=s1>&#39;6&#39;</span>: 16, <span class=s1>&#39;7&#39;</span>: 17, <span class=s1>&#39;8&#39;</span>: 18, <span class=s1>&#39;9&#39;</span>: 19<span class=o>}</span>
</span></span></code></pre></div><h2 id=prepare-the-datasets>Prepare the datasets</h2><p>To &ldquo;adapt&rdquo; our existing datasets, we recast our parsed streams and start using the new <code>RaggedTensor</code>s instead of the default sparse ones.</p><p>We also combine existing <code>feature</code>s into new ones by inserting separator tokens between the concatenated pieces.</p><p>Before handing the prepared streams of data to Keras, we still need to convert them to dense tensors. Most importantly, we pad the tensors to <code>len_max_input</code>, with generic zeros, for uniformity.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>caster</span><span class=p>(</span><span class=n>d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=n>k</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>d</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>SEP</span> <span class=o>=</span> <span class=n>qd</span><span class=o>.</span><span class=n>tokens</span><span class=p>[</span><span class=s1>&#39;:&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>SEP</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>adapter</span><span class=p>(</span><span class=n>d</span><span class=p>,</span> <span class=n>len_max_input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;defs&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>ss</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>fill</span><span class=p>([</span><span class=n>ds</span><span class=o>.</span><span class=n>nrows</span><span class=p>(),</span> <span class=mi>1</span><span class=p>],</span> <span class=n>qd</span><span class=o>.</span><span class=n>SEP</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;op&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>ds</span><span class=p>,</span> <span class=n>ss</span><span class=p>,</span> <span class=n>os</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=p>[[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>len_max_input</span> <span class=o>-</span> <span class=n>tf</span><span class=o>.</span><span class=n>shape</span><span class=p>(</span><span class=n>x</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]]])</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;res&#39;</span><span class=p>])[:,</span> <span class=p>:</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=m>1</span>
</span></span></code></pre></div><p>A newly created function will return the paths to our existing file shards.</p><p>And now we are ready to create our datasets, custom-adapted to our problem at hand:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>files</span><span class=p>(</span><span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>d</span> <span class=o>=</span> <span class=n>pth</span><span class=o>.</span><span class=n>Path</span><span class=p>(</span><span class=s1>&#39;/tmp/q/dataset&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>num_shards</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>i</span> <span class=o>=</span> <span class=s1>&#39;</span><span class=si>{:0&gt;4d}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=nb>str</span><span class=p>(</span><span class=n>d</span> <span class=o>/</span> <span class=sa>f</span><span class=s1>&#39;shard_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1>.tfrecords&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>dset_for</span><span class=p>(</span><span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>TFRecordDataset</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>files</span><span class=p>(</span><span class=n>ps</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>batch</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;defs&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;op&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;res&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>parse_example</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>fs</span><span class=p>))</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>caster</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>d</span><span class=p>:</span> <span class=n>adapter</span><span class=p>(</span><span class=n>d</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>constant</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>len_max_input</span><span class=p>)))</span>
</span></span></code></pre></div><h2 id=keras-masking-support>Keras masking support</h2><p>Next, we need to tell our custom Keras layers to support masking. Let&rsquo;s do it once for all of them in our own <code>Layer</code> base class. We simply inherit from it for all other layers.</p><p>Our first layer, the one receiving the to-be-masked input and needing to specifically calculate the versatile <code>bool</code> masking tensor, has to override the <code>compute_mask</code> method.</p><p>We could also transfer the mask calculation to another layer that would do it as an efficient side-effect of its own tasks. In that case we would use the 2 commented out lines:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Layer</span><span class=p>(</span><span class=n>kl</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>**</span><span class=n>kw</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>**</span><span class=n>kw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>supports_masking</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Masking</span><span class=p>(</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># self._compute_output_and_mask_jointly = True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute_mask</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>tf</span><span class=o>.</span><span class=n>not_equal</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># x._keras_mask = self.compute_mask(x)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span></code></pre></div><p>In order to turn our impossibly &ldquo;tight&rdquo; <code>int32</code> tokens into something more useful for machine learning, we need to <code>Embed</code> them into a much higher dimensional &ldquo;space&rdquo;.</p><p>Our embedding layer, however, is as simple as it gets: it first creates the embedding table and then does the actual lookup using the input tokens.</p><p>Once the embedded values are determined, we apply our straightforward <code>bool</code> masking cleanly, always resetting the masked-out, high dimensional values to <code>0</code> regardless of any &ldquo;learned&rdquo; adjustments.</p><p>During layer processing, Keras knows that we want to use the transparently hidden mask tensor from our included <code>mask=None</code> keyword argument in the <code>call</code> method&rsquo;s signature.</p><p>For <code>autograph</code>&rsquo;s sake we need to also explicitly check that the optional <code>mask</code> argument is <code>not None</code>; a simple intuitive <code>if mask:</code> would only trigger &ldquo;trace execution&rdquo; instead of &ldquo;graph execution&rdquo; in our later blogs.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Embed</span><span class=p>(</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_vocab</span><span class=p>,</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;emb&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>embedding_lookup</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>emb</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span> <span class=o>*=</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>mask</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>)[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><h2 id=attention-mechanism-with-masking>Attention mechanism with masking</h2><p>Our self-attention layer, fittingly called <code>Reflect</code>, does the absolute minimum required steps to implement the &ldquo;attention&rdquo; mechanism of the <code>transformer</code> architecture. An excellent, creative explanation of how it works is at <a href=http://jalammar.github.io/illustrated-transformer/>here</a>.</p><p>The masking tensor is being automatically supplied to the call by Keras. Once again, we only need to state our intention to mask by adding the <code>mask=None</code> keyword argument.</p><p>The actual masking calculation, based on our previously created <code>bool</code> tensor and specific for this layer only, is outright trivial. It simply replaces the to-be-masked values with large negatives:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Reflect</span><span class=p>(</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>build</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>shape</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=n>s</span><span class=o>**</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;q&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>s</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>s</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;v&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>s</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=n>build</span><span class=p>(</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsi,ij-&gt;bsj&#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>q</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsi,ij-&gt;bsj&#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsi,bzi-&gt;bsz&#39;</span><span class=p>,</span> <span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># tf.print(&#39; *** applying mask&#39;)</span>
</span></span><span class=line><span class=cl>            <span class=n>m</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>logical_not</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>m</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>)[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span> <span class=o>+=</span> <span class=n>m</span> <span class=o>*</span> <span class=o>-</span><span class=mf>1e9</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsi,ij-&gt;bsj&#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bsz,bzi-&gt;bsi&#39;</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>y</span><span class=p>),</span> <span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><p>We are now ready to create and compile our Keras <code>functional</code> model.</p><p>As the objective of this blog is to showcase masking, all the other necessary &ldquo;plumbing&rdquo; layers are the canned Keras variety ones.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>model_for</span><span class=p>(</span><span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>len_max_input</span><span class=p>,</span> <span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int32&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Masking</span><span class=p>()(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Embed</span><span class=p>(</span><span class=n>ps</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Reflect</span><span class=p>()(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>kl</span><span class=o>.</span><span class=n>Reshape</span><span class=p>((</span><span class=n>ps</span><span class=o>.</span><span class=n>len_max_input</span> <span class=o>*</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span><span class=p>,</span> <span class=p>))(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>kl</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_dense</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>kl</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_vocab</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;dbd&#39;</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=kc>None</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span> <span class=o>=</span> <span class=n>ks</span><span class=o>.</span><span class=n>Model</span><span class=p>(</span><span class=n>inputs</span><span class=o>=</span><span class=n>x</span><span class=p>,</span> <span class=n>outputs</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>optimizer</span><span class=o>=</span><span class=n>ps</span><span class=o>.</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>loss</span><span class=o>=</span><span class=n>ps</span><span class=o>.</span><span class=n>loss</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=n>ps</span><span class=o>.</span><span class=n>metric</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>summary</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>m</span>
</span></span></code></pre></div><p>The count of our parameters have slightly increased, otherwise they are the same as before. Please see the previous blog for the justification of the <code>Params</code> class and the overall scheme.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_batch</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_dense</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_hidden</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_vocab</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>vocab</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>len_max_input</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>losses</span><span class=o>.</span><span class=n>SparseCategoricalCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>metric</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>SparseCategoricalCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>num_epochs</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_shards</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>Adam</span><span class=p>(),</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>**</span><span class=n>kw</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>kw</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=nb>setattr</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=training-session>Training session</h2><p>Once we instantiate our parameters and our dataset, and using the already compiled model, we are ready to start a training session conveniently implemented by the Keras <code>fit</code> method.</p><p>Our aim is to use as much of the versatility, functionality and error checking that Keras provides, so using the model&rsquo;s <code>fit</code> method is all we need for now:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>main_graph</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>ds</span><span class=p>,</span> <span class=n>m</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ld</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s1>&#39;%Y%m</span><span class=si>%d</span><span class=s1>-%H%M%S&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ld</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;/tmp/q/logs/</span><span class=si>{</span><span class=n>ld</span><span class=si>}</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>cs</span> <span class=o>=</span> <span class=p>[</span><span class=n>ks</span><span class=o>.</span><span class=n>callbacks</span><span class=o>.</span><span class=n>TensorBoard</span><span class=p>(</span><span class=n>log_dir</span><span class=o>=</span><span class=n>ld</span><span class=p>,</span> <span class=n>histogram_freq</span><span class=o>=</span><span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>ds</span><span class=p>,</span> <span class=n>callbacks</span><span class=o>=</span><span class=n>cs</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=n>ps</span><span class=o>.</span><span class=n>num_epochs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>ps</span> <span class=o>=</span> <span class=n>qd</span><span class=o>.</span><span class=n>Params</span><span class=p>(</span><span class=o>**</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>main_graph</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>dset_for</span><span class=p>(</span><span class=n>ps</span><span class=p>),</span> <span class=n>model_for</span><span class=p>(</span><span class=n>ps</span><span class=p>))</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>  Model: <span class=s2>&#34;model&#34;</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  Layer <span class=o>(</span><span class=nb>type</span><span class=o>)</span>                 Output Shape              Param <span class=c1>#</span>
</span></span><span class=line><span class=cl>  <span class=o>=================================================================</span>
</span></span><span class=line><span class=cl>  input_1 <span class=o>(</span>InputLayer<span class=o>)</span>         <span class=o>[(</span>None, 20<span class=o>)]</span>              <span class=m>0</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  masking <span class=o>(</span>Masking<span class=o>)</span>            <span class=o>(</span>None, 20<span class=o>)</span>                <span class=m>0</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  embed <span class=o>(</span>Embed<span class=o>)</span>                <span class=o>(</span>None, 20, 15<span class=o>)</span>            <span class=m>300</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  reflect <span class=o>(</span>Reflect<span class=o>)</span>            <span class=o>(</span>None, 20, 15<span class=o>)</span>            <span class=m>675</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  reshape <span class=o>(</span>Reshape<span class=o>)</span>            <span class=o>(</span>None, 300<span class=o>)</span>               <span class=m>0</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  dense <span class=o>(</span>Dense<span class=o>)</span>                <span class=o>(</span>None, 150<span class=o>)</span>               <span class=m>45150</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  dbd <span class=o>(</span>Dense<span class=o>)</span>                  <span class=o>(</span>None, 20<span class=o>)</span>                <span class=nv>3020</span>
</span></span><span class=line><span class=cl>  <span class=o>=================================================================</span>
</span></span><span class=line><span class=cl>  Total params: 49,145
</span></span><span class=line><span class=cl>  Trainable params: 49,145
</span></span><span class=line><span class=cl>  Non-trainable params: <span class=m>0</span>
</span></span><span class=line><span class=cl>  _________________________________________________________________
</span></span><span class=line><span class=cl>  None
</span></span><span class=line><span class=cl>  Epoch 1/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 4s 4ms/step - loss: 1.7373 - sparse_categorical_crossentropy: 1.7373
</span></span><span class=line><span class=cl>  Epoch 2/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 1.4499 - sparse_categorical_crossentropy: 1.4499
</span></span><span class=line><span class=cl>  Epoch 3/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 1.3553 - sparse_categorical_crossentropy: 1.3553
</span></span><span class=line><span class=cl>  Epoch 4/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 1.2888 - sparse_categorical_crossentropy: 1.2888
</span></span><span class=line><span class=cl>  Epoch 5/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 1.2299 - sparse_categorical_crossentropy: 1.2299
</span></span><span class=line><span class=cl>  Epoch 6/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 1.1706 - sparse_categorical_crossentropy: 1.1706
</span></span><span class=line><span class=cl>  Epoch 7/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 1.1019 - sparse_categorical_crossentropy: 1.1019
</span></span><span class=line><span class=cl>  Epoch 8/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 1.0223 - sparse_categorical_crossentropy: 1.0223
</span></span><span class=line><span class=cl>  Epoch 9/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 0.9478 - sparse_categorical_crossentropy: 0.9478
</span></span><span class=line><span class=cl>  Epoch 10/10
</span></span><span class=line><span class=cl>  1000/1000 <span class=o>[==============================]</span> - 2s 2ms/step - loss: 0.8824 - sparse_categorical_crossentropy: 0.8824
</span></span></code></pre></div><p>With our TensorBoard <code>callback</code> in place, the model&rsquo;s <code>fit</code> method will generate the standard summaries that TensorBoard can conveniently visualize.</p><p>If you haven&rsquo;t run the below code, an already generated graph is <a href=generated/images/tech/masking.pdf>here</a>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#%load_ext tensorboard</span>
</span></span><span class=line><span class=cl><span class=c1>#%tensorboard --logdir /tmp/q/logs</span>
</span></span></code></pre></div><p>This concludes our blog, please see how to use the new <code>RaggedTensors</code> instead of masking by clicking on the next blog.</p></div></main></div><footer class="qal-footer py-5 bg-light"><div class=container><div class=row><div class=col-lg><a class=d-inline-flex href=../../><svg xmlns="http://www.w3.org/2000/svg" width="40" height="32" class="d-block me-2" viewBox="0 0 118 94" role="img"><title>Silcrow</title><path d="m67.476567 58.848956q2.916668 2.114585 4.375002 4.812503t1.458334 5.942711q0 5.250002-4.520836 8.421879-4.520835 3.208335-10.60938 3.208335-5.541669.0-9.406254-2.552085-3.864586-2.552084-3.864586-6.270836.0-2.151043 1.421876-3.500002 1.421876-1.3125 3.208335-1.3125 1.932293.0 3.026043 1.09375 1.093751 1.130209 1.786459 3.609377.911459 3.09896 2.296876 3.97396 1.385418.911459 3.208335.911459 2.187501.0 3.75521-1.239584t1.567709-3.026043q0-1.458334-1.020833-3.135418-1.057293-1.640626-6.708337-5.468753-6.526045-4.375002-9.369796-6.781253-2.843751-2.44271-4.375002-5.322919-1.531251-2.916669-1.531251-6.19792.0-3.09896 1.348959-5.432294 1.385417-2.333335 3.208335-3.427085 1.822918-1.130209 4.302085-1.713543-3.098959-2.260418-4.666668-4.921877-1.56771-2.66146-1.56771-5.76042.0-5.322919 4.484378-8.640629 4.484377-3.354168 10.901046-3.354168 5.395836.0 9.333338 2.515626t3.937502 6.088545q0 2.114584-1.494792 3.463543-1.494793 1.348959-3.427085 1.348959-1.895834.0-2.843752-.984375-.947917-1.020834-1.859376-3.718752-.838542-2.552085-2.078125-3.609377-1.239584-1.057292-3.463544-1.057292-2.296876.0-3.937502 1.276042-1.604167 1.276043-1.604167 3.062502.0 2.041667 1.567709 3.682293 1.531251 1.640626 7.473962 5.432294 5.578128 3.572919 8.239587 5.76042 2.697918 2.151043 4.229169 5.140627 1.567709 2.989585 1.567709 6.453128.0 4.411461-2.078126 7.218754-2.078126 2.807293-6.270836 4.010418zm1.166667-7.000003q0-3.682293-6.234378-8.531254-6.19792-4.885419-9.187505-4.885419-1.385417.0-2.661459 1.09375-1.239584 1.057293-1.239584 2.515627.0 3.463543 6.307295 8.421879 6.343753 4.958335 9.260421 4.958335 1.53125.0 2.625001-1.057292 1.130209-1.057292 1.130209-2.515626z" fill="#0"/></svg><span class=fs-5>&copy; 2022 Qnarre</span></a><ul class="list-unstyled small text-muted"><li class=mb-2>Software is our passion.</li></ul></div></div></div></footer><script src=../../js/bootstrap.bundle.min.js></script>
<script src=../../js/script.min.js></script></body></html>
<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A quick narrative analyzer for &lsquo;bipolar&rsquo; text"><meta name=author content="Qnarre - Software is our passion"><meta name=generator content="Hugo 0.99.0"><meta name=docsearch:language content="en"><meta name=docsearch:version content="0.1.0"><title>Custom Keras Layers Without The Drawbacks Â· Qnarre</title><link rel=canonical href=https://qnarre.com/tech/custom/><link href=../../css/bootstrap.min.css rel=stylesheet><link href=../../css/style.css rel=stylesheet><link rel=apple-touch-icon href=../../img/favs/apple-touch-icon.png sizes=180x180><link rel=icon href=../../img/favs/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=../../img/favs/favicon-16x16.png sizes=16x16 type=image/png><link rel=manifest href=../../img/favs/manifest.json><link rel=mask-icon href=../../img/favs/safari-pinned-tab color=#7952b3><link rel=icon href=../../img/favs/favicon.ico><meta name=theme-color content="#7952b3"></head><body><div class="skippy visually-hidden-focusable overflow-hidden"><div class=container-xl><a class="d-inline-flex p-2 m-1" href=#content>Skip to content</a></div></div><header class="navbar navbar-expand-md navbar-dark qal-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-2" href=../../><svg xmlns="http://www.w3.org/2000/svg" width="40" height="32" class="d-block my-1" viewBox="0 0 118 94" role="img"><title>Silcrow</title><path d="m67.476567 58.848956q2.916668 2.114585 4.375002 4.812503t1.458334 5.942711q0 5.250002-4.520836 8.421879-4.520835 3.208335-10.60938 3.208335-5.541669.0-9.406254-2.552085-3.864586-2.552084-3.864586-6.270836.0-2.151043 1.421876-3.500002 1.421876-1.3125 3.208335-1.3125 1.932293.0 3.026043 1.09375 1.093751 1.130209 1.786459 3.609377.911459 3.09896 2.296876 3.97396 1.385418.911459 3.208335.911459 2.187501.0 3.75521-1.239584t1.567709-3.026043q0-1.458334-1.020833-3.135418-1.057293-1.640626-6.708337-5.468753-6.526045-4.375002-9.369796-6.781253-2.843751-2.44271-4.375002-5.322919-1.531251-2.916669-1.531251-6.19792.0-3.09896 1.348959-5.432294 1.385417-2.333335 3.208335-3.427085 1.822918-1.130209 4.302085-1.713543-3.098959-2.260418-4.666668-4.921877-1.56771-2.66146-1.56771-5.76042.0-5.322919 4.484378-8.640629 4.484377-3.354168 10.901046-3.354168 5.395836.0 9.333338 2.515626t3.937502 6.088545q0 2.114584-1.494792 3.463543-1.494793 1.348959-3.427085 1.348959-1.895834.0-2.843752-.984375-.947917-1.020834-1.859376-3.718752-.838542-2.552085-2.078125-3.609377-1.239584-1.057292-3.463544-1.057292-2.296876.0-3.937502 1.276042-1.604167 1.276043-1.604167 3.062502.0 2.041667 1.567709 3.682293 1.531251 1.640626 7.473962 5.432294 5.578128 3.572919 8.239587 5.76042 2.697918 2.151043 4.229169 5.140627 1.567709 2.989585 1.567709 6.453128.0 4.411461-2.078126 7.218754-2.078126 2.807293-6.270836 4.010418zm1.166667-7.000003q0-3.682293-6.234378-8.531254-6.19792-4.885419-9.187505-4.885419-1.385417.0-2.661459 1.09375-1.239584 1.057293-1.239584 2.515627.0 3.463543 6.307295 8.421879 6.343753 4.958335 9.260421 4.958335 1.53125.0 2.625001-1.057292 1.130209-1.057292 1.130209-2.515626z" fill="#fff"/></svg></a><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#qalNavbar aria-controls=qalNavbar aria-expanded=false aria-label="Toggle navigation"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" class="bi" fill="currentcolor" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M2.5 11.5A.5.5.0 013 11h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5zm0-4A.5.5.0 013 7h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5zm0-4A.5.5.0 013 3h10a.5.5.0 010 1H3a.5.5.0 01-.5-.5z"/></svg></button><div class="collapse navbar-collapse" id=qalNavbar><hr class="d-md-none text-white-50"><ul class="navbar-nav flex-row flex-wrap qal-navbar-nav"><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../>Qnarre</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../modeling/>Modeling</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../semantics/>Semantics</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../analytics/>Analytics</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../reports/>Reports</a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=../../story/>The Story</a></li></ul><hr class="d-md-none text-white-50"><ul class="navbar-nav flex-row flex-wrap ms-md-auto"><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=https://twitter.com/ikifor target=_blank rel=noopener><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" class="navbar-nav-svg d-inline-block align-text-top" viewBox="0 0 512 416.32" role="img"><title>Twitter</title><path fill="currentcolor" d="M160.83 416.32c193.2.0 298.92-160.22 298.92-298.92.0-4.51.0-9-.2-13.52A214 214 0 00512 49.38a212.93 212.93.0 01-60.44 16.6 105.7 105.7.0 0046.3-58.19 209 209 0 01-66.79 25.37 105.09 105.09.0 00-181.73 71.91 116.12 116.12.0 002.66 24c-87.28-4.3-164.73-46.3-216.56-109.82A105.48 105.48.0 0068 159.6a106.27 106.27.0 01-47.53-13.11v1.43a105.28 105.28.0 0084.21 103.06 105.67 105.67.0 01-47.33 1.84 105.06 105.06.0 0098.14 72.94A210.72 210.72.0 0125 370.84a202.17 202.17.0 01-25-1.43 298.85 298.85.0 00160.83 46.92"/></svg><small class="d-md-none ms-2">Twitter</small></a></li><li class="nav-item col-6 col-md-auto"><a class="nav-link p-2" href=https://github.com/quantapix target=_blank rel=noopener><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" class="navbar-nav-svg d-inline-block align-text-top" viewBox="0 0 512 499.36" role="img"><title>GitHub</title><path fill="currentcolor" fill-rule="evenodd" d="M256 0C114.64.0.0 114.61.0 256c0 113.09 73.34 209 175.08 242.9 12.8 2.35 17.47-5.56 17.47-12.34.0-6.08-.22-22.18-.35-43.54-71.2 15.49-86.2-34.34-86.2-34.34-11.64-29.57-28.42-37.45-28.42-37.45-23.27-15.84 1.73-15.55 1.73-15.55 25.69 1.81 39.21 26.38 39.21 26.38 22.84 39.12 59.92 27.82 74.5 21.27 2.33-16.54 8.94-27.82 16.25-34.22-56.84-6.43-116.6-28.43-116.6-126.49.0-27.95 10-50.8 26.35-68.69-2.63-6.48-11.42-32.5 2.51-67.75.0.0 21.49-6.88 70.4 26.24a242.65 242.65.0 01128.18.0c48.87-33.13 70.33-26.24 70.33-26.24 14 35.25 5.18 61.27 2.55 67.75 16.41 17.9 26.31 40.75 26.31 68.69.0 98.35-59.85 120-116.88 126.32 9.19 7.9 17.38 23.53 17.38 47.41.0 34.22-.31 61.83-.31 70.23.0 6.85 4.61 14.81 17.6 12.31C438.72 464.97 512 369.08 512 256.02 512 114.62 397.37.0 256 0z"/></svg><small class="d-md-none ms-2">GitHub</small></a></li></ul><a class="btn btn-qal-download d-lg-inline-block my-2 my-md-0 ms-md-3" href=https://femfas.net/>femfas.net</a></div></nav></header><div class="container-xxl my-md-4 qal-layout"><aside class=qal-sidebar><nav class="collapse qal-links" id=qal-docs-nav aria-label="Nav links"><ul class="list-unstyled mb-0 py-3 pt-md-1"><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#modeling-collapse aria-expanded=false>
Modeling</button><div class=collapse id=modeling-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../modeling/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../modeling/simulation class="d-inline-flex align-items-center rounded">Judicial Simulation</a></li><li><a href=../../modeling/concepts class="d-inline-flex align-items-center rounded">Conceptual Model</a></li><li><a href=../../modeling/report class="d-inline-flex align-items-center rounded">Sample Report</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#semantics-collapse aria-expanded=false>
Semantics</button><div class=collapse id=semantics-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../semantics/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../semantics/simulation class="d-inline-flex align-items-center rounded">Judicial Simulation</a></li><li><a href=../../semantics/concepts class="d-inline-flex align-items-center rounded">Conceptual Model</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#analytics-collapse aria-expanded=false>
Analytics</button><div class=collapse id=analytics-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../analytics/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../analytics/prepare class="d-inline-flex align-items-center rounded">Preparing Documents</a></li><li><a href=../../analytics/extract class="d-inline-flex align-items-center rounded">Extracting Narratives</a></li><li><a href=../../analytics/output class="d-inline-flex align-items-center rounded">Standardized Output</a></li><li><a href=../../analytics/graph class="d-inline-flex align-items-center rounded">Conflict Graph</a></li><li><a href=../../analytics/analyze class="d-inline-flex align-items-center rounded">Irrefutable Analytics</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#reports-collapse aria-expanded=false>
Reports</button><div class=collapse id=reports-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../reports/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../reports/prepare class="d-inline-flex align-items-center rounded">Generating Reports</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#story-collapse aria-expanded=false>
The Story</button><div class=collapse id=story-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../story/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../story/about class="d-inline-flex align-items-center rounded">About</a></li><li><a href=../../story/blog class="d-inline-flex align-items-center rounded">Blog</a></li></ul></div></li><li class=mb-1><button class="btn d-inline-flex align-items-center rounded" data-bs-toggle=collapse data-bs-target=#tech-collapse aria-expanded=true aria-current=true>
Available Tech</button><div class="collapse show" id=tech-collapse><ul class="list-unstyled fw-normal pb-1 small"><li><a href=../../tech/./ class="d-inline-flex align-items-center rounded">Overview</a></li><li><a href=../../tech/trackable class="d-inline-flex align-items-center rounded">Trackable Persistence</a></li><li><a href=../../tech/gpus class="d-inline-flex align-items-center rounded">Many Smaller GPUs</a></li><li><a href=../../tech/dataset class="d-inline-flex align-items-center rounded">Datasets</a></li><li><a href=../../tech/masking class="d-inline-flex align-items-center rounded">Unified Masking</a></li><li><a href=../../tech/ragged class="d-inline-flex align-items-center rounded">Ragged Tensors</a></li><li><a href=../../tech/layers class="d-inline-flex align-items-center rounded">Layers Simplified</a></li><li><a href=../../tech/custom class="d-inline-flex align-items-center rounded active" aria-current=page>Custom Layers</a></li><li><a href=../../tech/autograph class="d-inline-flex align-items-center rounded">Autograph</a></li><li><a href=../../tech/metrics class="d-inline-flex align-items-center rounded">Modular Metrics</a></li><li><a href=../../tech/callbacks class="d-inline-flex align-items-center rounded">Extended Callbacks</a></li></ul></div></li></ul></nav></aside><main class="qal-main order-1"><div class="qal-intro ps-lg-4"><div class="d-md-flex flex-md-row align-items-center justify-content-between"><h1 class=qal-title id=content>Custom Keras Layers Without The Drawbacks</h1></div><p class=qal-lead></p></div><div class="qal-toc mt-4 mb-5 my-md-0 ps-xl-3 mb-lg-5 text-muted"><strong class="d-block h6 my-2 pb-2 border-bottom">On this page</strong><nav id=TableOfContents><ul><li><a href=#formatter-expanded>&ldquo;Formatter&rdquo; expanded</a></li><li><a href=#dataset-adapter>Dataset adapter</a></li><li><a href=#frames-layer>Frames layer</a></li><li><a href=#encode-decode-and-debed-layers>Encode, decode and debed layers</a></li><li><a href=#updated-lightweight-modules>Updated lightweight modules</a></li><li><a href=#updates-for-our-model>Updates for our model</a></li><li><a href=#training-session>Training session</a></li></ul></nav></div><div class="qal-content ps-lg-4"><p>In this blog we continue to train our computer to &ldquo;understand&rdquo; elementary symbolic arithmetic.</p><p>We slightly change our approach however. Instead of having fixed input/context for our encoder/decoder stacks, we follow the idea of &ldquo;sliding contexts&rdquo; from this <a href=https://arxiv.org/pdf/1901.02860.pdf>paper</a>.</p><p>In addition, we continue to architect our model with a mixture of &ldquo;validated&rdquo; Keras <code>layers</code> as well as light-weight <code>Modules</code> containing bare TF ops.</p><p>Our objective is to ultimately arrive at a model representable by the <a href=generated/images/tech/custom.pdf>graph</a> and <a href=https://github.com/quantapix/qnarre/blob/master/docs/advanced_tf/custom.ipynb>runnable example</a>.</p><p>Just as before, we need to prep our environment to run any meaningful code:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>dataset</span> <span class=k>as</span> <span class=nn>qd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>layers</span> <span class=k>as</span> <span class=nn>ql</span>
</span></span><span class=line><span class=cl><span class=n>ks</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span>
</span></span><span class=line><span class=cl><span class=n>kl</span> <span class=o>=</span> <span class=n>ks</span><span class=o>.</span><span class=n>layers</span>
</span></span></code></pre></div><p>Before we start, we need to increase our dataset slightly as the training steps are becoming more meaningful.</p><p>Calling the <code>dump_dset</code> function with a parameters instance will update our stored sharded binary files:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dump_dset</span><span class=p>(</span><span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ps</span><span class=o>.</span><span class=n>max_val</span> <span class=o>=</span> <span class=mi>10000</span>
</span></span><span class=line><span class=cl>    <span class=n>ps</span><span class=o>.</span><span class=n>num_samples</span> <span class=o>=</span> <span class=mi>1000</span>  <span class=c1># 100000</span>
</span></span><span class=line><span class=cl>    <span class=n>ps</span><span class=o>.</span><span class=n>num_shards</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>    <span class=n>fs</span> <span class=o>=</span> <span class=p>[</span><span class=n>f</span> <span class=k>for</span> <span class=n>f</span> <span class=ow>in</span> <span class=n>qd</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>ps</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>ps</span><span class=o>.</span><span class=n>dim_batch</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>fs</span><span class=p>)</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>adapter</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;dumped </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1> batches of </span><span class=si>{</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_batch</span><span class=si>}</span><span class=s1> samples each&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>fs</span>
</span></span></code></pre></div><p>For verification purposes, loading our already created meta data from the sources gives us:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>vocab</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>SPC</span><span class=p>,</span> <span class=n>qd</span><span class=o>.</span><span class=n>SEP</span><span class=p>,</span> <span class=n>qd</span><span class=o>.</span><span class=n>STP</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>  <span class=o>(</span><span class=s1>&#39; &#39;</span>, <span class=s1>&#39;:&#39;</span>, <span class=s1>&#39;|&#39;</span>, <span class=s1>&#39;x&#39;</span>, <span class=s1>&#39;y&#39;</span>, <span class=s1>&#39;=&#39;</span>, <span class=s1>&#39;,&#39;</span>, <span class=s1>&#39;+&#39;</span>, <span class=s1>&#39;-&#39;</span>, <span class=s1>&#39;*&#39;</span>, <span class=s1>&#39;0&#39;</span>, <span class=s1>&#39;1&#39;</span>, <span class=s1>&#39;2&#39;</span>, <span class=s1>&#39;3&#39;</span>, <span class=s1>&#39;4&#39;</span>, <span class=s1>&#39;5&#39;</span>, <span class=s1>&#39;6&#39;</span>, <span class=s1>&#39;7&#39;</span>, <span class=s1>&#39;8&#39;</span>, <span class=s1>&#39;9&#39;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=m>0</span> <span class=m>1</span> <span class=m>2</span>
</span></span></code></pre></div><h2 id=formatter-expanded>&ldquo;Formatter&rdquo; expanded</h2><p>We also need to expand our previously used <code>formatter</code>.</p><p>As we intend to concatenate subsequent inputs in our &ldquo;sliding context&rdquo;, we need to end the result feature, <code>res</code>, of our samples with our <code>STP = "|"</code> token.</p><p>We have started to use <code>tf.debugging.assert</code>s to increase our confidence in the correctness of our data. Later we will be able to switch these out with the familiar Python <code>asserts</code>.</p><p>Our <code>formatter</code> comes with an other significant adjustment.</p><p>We intend to feed both our <code>encoder</code> and our <code>decoder</code> with inputs. Namely, the encoder gets the concatenated <code>defs</code> and <code>op</code> features, while the decoder gets either a fully or a partially blanked <code>res</code>.</p><p>Our dataset will supply an <code>enc</code>, a <code>dec</code> and a <code>tgt</code> (the full correct result of the math expression in the sample) tensors. The <code>rand_blank</code> function does the quick (inline) random blanking, or masking, of the arithmetic result to be fed into our <code>decoder</code> as the <code>des</code> tensor.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>formatter</span><span class=p>(</span><span class=n>d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;defs&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>n</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>nrows</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;op&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>tf</span><span class=o>.</span><span class=n>debugging</span><span class=o>.</span><span class=n>assert_equal</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>nrows</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>ss</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>fill</span><span class=p>([</span><span class=n>n</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>qd</span><span class=o>.</span><span class=n>SEP</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>enc</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>ds</span><span class=p>,</span> <span class=n>ss</span><span class=p>,</span> <span class=n>os</span><span class=p>,</span> <span class=n>ss</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>rs</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_sparse</span><span class=p>(</span><span class=n>d</span><span class=p>[</span><span class=s1>&#39;res&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>tf</span><span class=o>.</span><span class=n>debugging</span><span class=o>.</span><span class=n>assert_equal</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>rs</span><span class=o>.</span><span class=n>nrows</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>tgt</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>rs</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>fill</span><span class=p>([</span><span class=n>n</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>qd</span><span class=o>.</span><span class=n>STP</span><span class=p>)],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>rand_blank</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>flat_values</span>
</span></span><span class=line><span class=cl>        <span class=n>mv</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>shape</span><span class=p>(</span><span class=n>y</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>mv</span> <span class=o>//</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>        <span class=n>i</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>([</span><span class=n>s</span><span class=p>],</span> <span class=n>maxval</span><span class=o>=</span><span class=n>mv</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>)[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>tensor_scatter_nd_update</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>i</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>zeros</span><span class=p>([</span><span class=n>s</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span><span class=o>.</span><span class=n>with_flat_values</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;enc&#39;</span><span class=p>:</span> <span class=n>enc</span><span class=p>,</span> <span class=s1>&#39;dec&#39;</span><span class=p>:</span> <span class=n>rand_blank</span><span class=p>(</span><span class=n>tgt</span><span class=p>),</span> <span class=s1>&#39;tgt&#39;</span><span class=p>:</span> <span class=n>tgt</span><span class=p>}</span>
</span></span></code></pre></div><p>In order for our dataset to be usable, we also need to update our <code>adapter</code>.</p><p>We continue to split our input ragged tensors into their components, and as we now have 3 ragged inputs: <code>enc</code>, <code>dec</code> and <code>tgt</code>, the total number of dense input tensors to our model will be 6.</p><p>The adapter needs to also supply our <code>tgt</code> dense tensor to the canned <code>loss</code> and <code>metrics</code> components that drive the gradient calculations.</p><p>In addition, we chose to add <code>tgt</code>, or its two components, to our inputs as well. This duplication gives us the chance of feeding correct arithmetic results into our &ldquo;sliding context&rdquo;.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>adapter</span><span class=p>(</span><span class=n>d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>enc</span><span class=p>,</span> <span class=n>dec</span><span class=p>,</span> <span class=n>tgt</span> <span class=o>=</span> <span class=n>d</span><span class=p>[</span><span class=s1>&#39;enc&#39;</span><span class=p>],</span> <span class=n>d</span><span class=p>[</span><span class=s1>&#39;dec&#39;</span><span class=p>],</span> <span class=n>d</span><span class=p>[</span><span class=s1>&#39;tgt&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>enc</span><span class=o>.</span><span class=n>flat_values</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>enc</span><span class=o>.</span><span class=n>row_splits</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>dec</span><span class=o>.</span><span class=n>flat_values</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>dec</span><span class=o>.</span><span class=n>row_splits</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>tgt</span><span class=o>.</span><span class=n>flat_values</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>tgt</span><span class=o>.</span><span class=n>row_splits</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><h2 id=dataset-adapter>Dataset adapter</h2><p>Our new dataset creator function, <code>dset_for</code> is as follows.</p><p>We have added an optionally overridable <code>adapter</code> argument to be used later.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dset_for</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>adapter</span><span class=o>=</span><span class=n>adapter</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>TFRecordDataset</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>files</span><span class=p>(</span><span class=n>ps</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>take</span><span class=p>(</span><span class=mi>100</span><span class=p>)</span><span class=o>.</span><span class=n>batch</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;defs&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;op&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;res&#39;</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>VarLenFeature</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>int64</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>tf</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>parse_example</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>fs</span><span class=p>))</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>caster</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>formatter</span><span class=p>)</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>adapter</span><span class=p>)</span>
</span></span></code></pre></div><p>As we now have 3 pairs of input tensors, that we need to convert back into <code>RaggedTensor</code>s, we quickly add a <code>ToRagged</code> convenience layer that can be seamlessly eliminated once the Keras <code>Input</code>s start properly supporting the <code>ragged=True</code> keyword argument:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ToRagged</span><span class=p>(</span><span class=n>kl</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>ys</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>i</span> <span class=o>*=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>            <span class=n>fv</span><span class=p>,</span> <span class=n>rs</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span> <span class=o>+</span> <span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>ys</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>RaggedTensor</span><span class=o>.</span><span class=n>from_row_splits</span><span class=p>(</span><span class=n>fv</span><span class=p>,</span> <span class=n>rs</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>ys</span>
</span></span></code></pre></div><h2 id=frames-layer>Frames layer</h2><p>The <code>Frames</code> layer is the new significant addition to our code.</p><p>With every new encoder input sequence of tokens <code>xe</code>, it first concatenates the <code>prev</code> stored context with <code>xe</code> and then stores the result in <code>ye</code>.</p><p>Then it updates the <code>prev</code> variable with the concatenation of <code>ye</code> and the passed in correct arithmetic result <code>xt</code>. The resulting <code>prev</code> is to be used in the next cycle.</p><p>The computations are slightly more complex due to using the raggedness of the inputs to satisfy the continuous, seamlessly &ldquo;sliding context&rdquo; requirement.</p><p>The layer also returns the &ldquo;row_lengths&rdquo; tensors for both <code>enc</code> and <code>dec</code> inputs. They will be used later for propagating the input token sequences&rsquo; &ldquo;raggedness&rdquo;.</p><p>The entire <code>Frames</code> layer works exclusively with tokens, as we don&rsquo;t want to keep stale embedding calculations around in our &ldquo;sliding context&rdquo;.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Frames</span><span class=p>(</span><span class=n>ql</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>  <span class=c1># , dynamic=True)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_batch</span><span class=p>,</span> <span class=n>ps</span><span class=o>.</span><span class=n>width_enc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>kw</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=n>initializer</span><span class=o>=</span><span class=s1>&#39;zeros&#39;</span><span class=p>,</span> <span class=n>trainable</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>use_resource</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>prev</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=s1>&#39;prev&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=n>s</span><span class=p>,</span> <span class=o>**</span><span class=n>kw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>xe</span><span class=p>,</span> <span class=n>xd</span><span class=p>,</span> <span class=n>xt</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>ye</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>prev</span><span class=p>,</span> <span class=n>xe</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>el</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>xe</span><span class=o>.</span><span class=n>row_lengths</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ye</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>gather_nd</span><span class=p>(</span><span class=n>ye</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>calc_idxs</span><span class=p>(</span><span class=n>el</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ps</span><span class=o>.</span><span class=n>width_dec</span> <span class=o>-</span> <span class=n>xd</span><span class=o>.</span><span class=n>bounding_shape</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>out_type</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>yd</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span><span class=n>xd</span><span class=o>.</span><span class=n>to_tensor</span><span class=p>(),</span> <span class=p>[[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>c</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>        <span class=n>dl</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>xd</span><span class=o>.</span><span class=n>row_lengths</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>ye</span><span class=p>,</span> <span class=n>xt</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tl</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>xt</span><span class=o>.</span><span class=n>row_lengths</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>gather_nd</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>calc_idxs</span><span class=p>(</span><span class=n>tl</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>prev</span><span class=o>.</span><span class=n>assign</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>ye</span><span class=p>,</span> <span class=n>el</span><span class=p>,</span> <span class=n>yd</span><span class=p>,</span> <span class=n>dl</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>calc_idxs</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>lens</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>b</span><span class=p>,</span> <span class=n>w</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_batch</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>ps</span><span class=o>.</span><span class=n>width_enc</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>broadcast_to</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=n>b</span><span class=p>)[:,</span> <span class=kc>None</span><span class=p>],</span> <span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=n>w</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>i</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>range</span><span class=p>(</span><span class=n>w</span><span class=p>)[</span><span class=kc>None</span><span class=p>,</span> <span class=p>]</span> <span class=o>+</span> <span class=n>lens</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>y</span><span class=p>,</span> <span class=n>i</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><p>As our <code>Frames</code> layer returns fixed-width dense tensors once again, we can re-adjust our carried-over <code>Embed</code> layer to use the straight <code>embedding_lookup</code> instead.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Embed</span><span class=p>(</span><span class=n>ql</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>ps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_vocab</span><span class=p>,</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=s1>&#39;emb&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span><span class=p>,</span> <span class=n>lens</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>embedding_lookup</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>emb</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>*=</span> <span class=n>y</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>**</span><span class=mf>0.5</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>y</span><span class=p>,</span> <span class=n>lens</span><span class=p>]</span>
</span></span></code></pre></div><h2 id=encode-decode-and-debed-layers>Encode, decode and debed layers</h2><p>We update the <code>Encode</code> and <code>Decode</code> layers with the addition of the <code>tf.function</code> decorators for the <code>call</code> methods.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Encode</span><span class=p>(</span><span class=n>ql</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>ps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>width</span> <span class=o>=</span> <span class=n>ps</span><span class=o>.</span><span class=n>width_enc</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>encs</span> <span class=o>=</span> <span class=p>[</span><span class=n>Encoder</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=sa>f</span><span class=s1>&#39;enc_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_stacks</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>e</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>encs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span> <span class=o>=</span> <span class=n>e</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Decode</span><span class=p>(</span><span class=n>ql</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>ps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>width</span> <span class=o>=</span> <span class=n>ps</span><span class=o>.</span><span class=n>width_dec</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>decs</span> <span class=o>=</span> <span class=p>[</span><span class=n>Decoder</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=sa>f</span><span class=s1>&#39;dec_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_stacks</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span><span class=p>,</span> <span class=n>ye</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=n>x</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>decs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>y</span> <span class=o>=</span> <span class=n>d</span><span class=p>(</span><span class=n>y</span> <span class=o>+</span> <span class=p>[</span><span class=n>ye</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><p>Our <code>Debed</code> layer is also largely a carry-over, with the adjustment for the now fixed-width tensors.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Debed</span><span class=p>(</span><span class=n>ql</span><span class=o>.</span><span class=n>Layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>ps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dbd</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=s1>&#39;dbd&#39;</span><span class=p>,</span> <span class=p>[</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span><span class=p>,</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_vocab</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>call</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span><span class=p>,</span> <span class=n>lens</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>s</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>shape</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=p>[</span><span class=n>s</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>s</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dbd</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=p>[</span><span class=n>s</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>s</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=p>[:,</span> <span class=p>:</span><span class=n>tf</span><span class=o>.</span><span class=n>math</span><span class=o>.</span><span class=n>reduce_max</span><span class=p>(</span><span class=n>lens</span><span class=p>),</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><h2 id=updated-lightweight-modules>Updated lightweight modules</h2><p>We update the <code>Encoder</code> and <code>Decoder</code> modules with the addition of the <code>tf.function</code> decorators for the <code>__call__</code> methods:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Encoder</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>layer</span><span class=p>,</span> <span class=n>name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>name_scope</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>reflect</span> <span class=o>=</span> <span class=n>Attention</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=s1>&#39;refl&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>conclude</span> <span class=o>=</span> <span class=n>Conclusion</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=s1>&#39;conc&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reflect</span><span class=p>(</span><span class=n>y</span> <span class=o>+</span> <span class=p>[</span><span class=n>y</span><span class=p>[</span><span class=mi>0</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conclude</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Decoder</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>layer</span><span class=p>,</span> <span class=n>name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>name_scope</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>reflect</span> <span class=o>=</span> <span class=n>Attention</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=s1>&#39;refl&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>consider</span> <span class=o>=</span> <span class=n>Attention</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=s1>&#39;cnsd&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>conclude</span> <span class=o>=</span> <span class=n>Conclusion</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=s1>&#39;conc&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span><span class=p>,</span> <span class=n>ye</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=n>x</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reflect</span><span class=p>(</span><span class=n>y</span> <span class=o>+</span> <span class=p>[</span><span class=n>y</span><span class=p>[</span><span class=mi>0</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>consider</span><span class=p>(</span><span class=n>y</span> <span class=o>+</span> <span class=p>[</span><span class=n>ye</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conclude</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>y</span>
</span></span></code></pre></div><p>The same applies to our new <code>Attention</code> module:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Attention</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>layer</span><span class=p>,</span> <span class=n>name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>h</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=n>h</span><span class=o>**</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>name_scope</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>q</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=s1>&#39;q&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>k</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>v</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>add_weight</span><span class=p>(</span><span class=s1>&#39;v&#39;</span><span class=p>,</span> <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=p>,</span> <span class=n>lens</span><span class=p>,</span> <span class=n>ctx</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>off</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>math</span><span class=o>.</span><span class=n>reduce_max</span><span class=p>(</span><span class=n>lens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bni,ij-&gt;bnj&#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>[:,</span> <span class=o>-</span><span class=n>off</span><span class=p>:,</span> <span class=p>:],</span> <span class=bp>self</span><span class=o>.</span><span class=n>q</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bni,ij-&gt;bnj&#39;</span><span class=p>,</span> <span class=n>ctx</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bni,bmi-&gt;bnm&#39;</span><span class=p>,</span> <span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># use lens</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>y</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bni,ij-&gt;bnj&#39;</span><span class=p>,</span> <span class=n>ctx</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>einsum</span><span class=p>(</span><span class=s1>&#39;bnm,bmi-&gt;bni&#39;</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>concat</span><span class=p>([</span><span class=n>x</span><span class=p>[:,</span> <span class=p>:</span><span class=o>-</span><span class=n>off</span><span class=p>,</span> <span class=p>:],</span> <span class=n>y</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>y</span><span class=p>,</span> <span class=n>lens</span><span class=p>]</span>
</span></span></code></pre></div><p>The same applies to our new <code>Conclusion</code> module as well:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Conclusion</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>layer</span><span class=p>,</span> <span class=n>name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>layer</span> <span class=o>=</span> <span class=n>layer</span>
</span></span><span class=line><span class=cl>        <span class=n>ps</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>ps</span>
</span></span><span class=line><span class=cl>        <span class=n>w</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>width</span> <span class=o>*</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>name_scope</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>s</span> <span class=o>=</span> <span class=p>[</span><span class=n>w</span><span class=p>,</span> <span class=n>ps</span><span class=o>.</span><span class=n>dim_dense</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>inflate</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=s1>&#39;infl&#39;</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>s</span> <span class=o>=</span> <span class=p>[</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_dense</span><span class=p>,</span> <span class=n>w</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>deflate</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=n>layer</span><span class=p>,</span> <span class=s1>&#39;defl&#39;</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span><span class=p>,</span> <span class=n>lens</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>w</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layer</span><span class=o>.</span><span class=n>width</span>
</span></span><span class=line><span class=cl>        <span class=n>d</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layer</span><span class=o>.</span><span class=n>ps</span><span class=o>.</span><span class=n>dim_hidden</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>w</span> <span class=o>*</span> <span class=n>d</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>inflate</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>deflate</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>d</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>y</span><span class=p>,</span> <span class=n>lens</span><span class=p>]</span>
</span></span></code></pre></div><p>To add the <code>tf.function</code> decorator to our <code>Dense</code> module, we simply inherit from the previous version:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Dense</span><span class=p>(</span><span class=n>ql</span><span class=o>.</span><span class=n>Dense</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nd>@tf</span><span class=o>.</span><span class=n>function</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__call__</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=updates-for-our-model>Updates for our model</h2><p>Our model instance needs to be updated as well to use the newly defined components.</p><p>Another significant change is the addition of the &ldquo;row_lengths&rdquo; tensor (received directly from the ragged tensors) to all the now fixed-width input and output dense tensors.</p><p>Once again, we were able to return to using dense tensors for our inputs, despite the &ldquo;raggedness&rdquo; of our samples, because we adopted the &ldquo;sliding context&rdquo; strategy, thus smoothly concatenating an entire &ldquo;history&rdquo; of inputs and correct arithmetic results, into our &ldquo;working set&rdquo;:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>model_for</span><span class=p>(</span><span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=p>[</span><span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int32&#39;</span><span class=p>),</span> <span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int64&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>+=</span> <span class=p>[</span><span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int32&#39;</span><span class=p>),</span> <span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int64&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>+=</span> <span class=p>[</span><span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int32&#39;</span><span class=p>),</span> <span class=n>ks</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(),</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int64&#39;</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>ToRagged</span><span class=p>()(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Frames</span><span class=p>(</span><span class=n>ps</span><span class=p>)(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>embed</span> <span class=o>=</span> <span class=n>Embed</span><span class=p>(</span><span class=n>ps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ye</span> <span class=o>=</span> <span class=n>Encode</span><span class=p>(</span><span class=n>ps</span><span class=p>)(</span><span class=n>embed</span><span class=p>(</span><span class=n>y</span><span class=p>[:</span><span class=mi>2</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=n>yd</span> <span class=o>=</span> <span class=n>Decode</span><span class=p>(</span><span class=n>ps</span><span class=p>)(</span><span class=n>embed</span><span class=p>(</span><span class=n>y</span><span class=p>[</span><span class=mi>2</span><span class=p>:])</span> <span class=o>+</span> <span class=p>[</span><span class=n>ye</span><span class=p>[</span><span class=mi>0</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>Debed</span><span class=p>(</span><span class=n>ps</span><span class=p>)(</span><span class=n>yd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span> <span class=o>=</span> <span class=n>ks</span><span class=o>.</span><span class=n>Model</span><span class=p>(</span><span class=n>inputs</span><span class=o>=</span><span class=n>x</span><span class=p>,</span> <span class=n>outputs</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>m</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>optimizer</span><span class=o>=</span><span class=n>ps</span><span class=o>.</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>loss</span><span class=o>=</span><span class=n>ps</span><span class=o>.</span><span class=n>loss</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=n>ps</span><span class=o>.</span><span class=n>metric</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>summary</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>m</span>
</span></span></code></pre></div><p>Our parameters need to be expanded with the addition of the values for the now fixed widths of both our <code>encoder</code> and <code>decoder</code> stacks.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_batch</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_dense</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_hidden</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_stacks</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dim_vocab</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>qd</span><span class=o>.</span><span class=n>vocab</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>losses</span><span class=o>.</span><span class=n>SparseCategoricalCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>metric</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>SparseCategoricalCrossentropy</span><span class=p>(</span><span class=n>from_logits</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>num_epochs</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_shards</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>=</span><span class=n>ks</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>Adam</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>width_dec</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>width_enc</span><span class=o>=</span><span class=mi>25</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h2 id=training-session>Training session</h2><p>By firing up our training session, we can confirm the model&rsquo;s layers and connections. The listing of a short session follows.</p><p>We can easily adjust the parameters to tailor the length of the sessions to our objectives.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ps</span> <span class=o>=</span> <span class=n>qd</span><span class=o>.</span><span class=n>Params</span><span class=p>(</span><span class=o>**</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>masking</span> <span class=k>as</span> <span class=nn>qm</span>
</span></span><span class=line><span class=cl><span class=n>qm</span><span class=o>.</span><span class=n>main_graph</span><span class=p>(</span><span class=n>ps</span><span class=p>,</span> <span class=n>dset_for</span><span class=p>(</span><span class=n>ps</span><span class=p>),</span> <span class=n>model_for</span><span class=p>(</span><span class=n>ps</span><span class=p>))</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>  Model: <span class=s2>&#34;model_1&#34;</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  Layer <span class=o>(</span><span class=nb>type</span><span class=o>)</span>                    Output Shape         Param <span class=c1>#     Connected to</span>
</span></span><span class=line><span class=cl>  <span class=o>==================================================================================================</span>
</span></span><span class=line><span class=cl>  input_7 <span class=o>(</span>InputLayer<span class=o>)</span>            <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  input_8 <span class=o>(</span>InputLayer<span class=o>)</span>            <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  input_9 <span class=o>(</span>InputLayer<span class=o>)</span>            <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  input_10 <span class=o>(</span>InputLayer<span class=o>)</span>           <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  input_11 <span class=o>(</span>InputLayer<span class=o>)</span>           <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  input_12 <span class=o>(</span>InputLayer<span class=o>)</span>           <span class=o>[(</span>None,<span class=o>)]</span>            <span class=m>0</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  to_ragged_1 <span class=o>(</span>ToRagged<span class=o>)</span>          <span class=o>[(</span>None, None<span class=o>)</span>, <span class=o>(</span>None <span class=m>0</span>           input_7<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   input_8<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   input_9<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   input_10<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   input_11<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   input_12<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  frames_1 <span class=o>(</span>Frames<span class=o>)</span>               <span class=o>[(</span>5, 25<span class=o>)</span>, <span class=o>(</span>None,<span class=o>)</span>, <span class=o>(</span> <span class=m>125</span>         to_ragged_1<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   to_ragged_1<span class=o>[</span>0<span class=o>][</span>1<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   to_ragged_1<span class=o>[</span>0<span class=o>][</span>2<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  embed_1 <span class=o>(</span>Embed<span class=o>)</span>                 multiple             <span class=m>120</span>         frames_1<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   frames_1<span class=o>[</span>0<span class=o>][</span>1<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   frames_1<span class=o>[</span>0<span class=o>][</span>2<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   frames_1<span class=o>[</span>0<span class=o>][</span>3<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  encode_1 <span class=o>(</span>Encode<span class=o>)</span>               <span class=o>[(</span>None, 25, 6<span class=o>)</span>, <span class=o>(</span>Non <span class=m>90516</span>       embed_1<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   embed_1<span class=o>[</span>0<span class=o>][</span>1<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  decode_1 <span class=o>(</span>Decode<span class=o>)</span>               <span class=o>[(</span>None, 15, 6<span class=o>)</span>, <span class=o>(</span>Non <span class=m>54732</span>       embed_1<span class=o>[</span>1<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   embed_1<span class=o>[</span>1<span class=o>][</span>1<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   encode_1<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  debed_1 <span class=o>(</span>Debed<span class=o>)</span>                 <span class=o>(</span>None, None, None<span class=o>)</span>   <span class=m>140</span>         decode_1<span class=o>[</span>0<span class=o>][</span>0<span class=o>]</span>
</span></span><span class=line><span class=cl>                                                                   decode_1<span class=o>[</span>0<span class=o>][</span>1<span class=o>]</span>
</span></span><span class=line><span class=cl>  <span class=o>==================================================================================================</span>
</span></span><span class=line><span class=cl>  Total params: 145,633
</span></span><span class=line><span class=cl>  Trainable params: 145,508
</span></span><span class=line><span class=cl>  Non-trainable params: <span class=m>125</span>
</span></span><span class=line><span class=cl>  __________________________________________________________________________________________________
</span></span><span class=line><span class=cl>  None
</span></span><span class=line><span class=cl>  Epoch 1/5
</span></span><span class=line><span class=cl>  20/20 <span class=o>[==============================]</span> - 20s 1s/step - loss: 2.6308 - sparse_categorical_crossentropy: 2.6164
</span></span><span class=line><span class=cl>  Epoch 2/5
</span></span><span class=line><span class=cl>  20/20 <span class=o>[==============================]</span> - 0s 11ms/step - loss: 2.1488 - sparse_categorical_crossentropy: 2.1325
</span></span><span class=line><span class=cl>  Epoch 3/5
</span></span><span class=line><span class=cl>  20/20 <span class=o>[==============================]</span> - 0s 11ms/step - loss: 1.8967 - sparse_categorical_crossentropy: 1.8844
</span></span><span class=line><span class=cl>  Epoch 4/5
</span></span><span class=line><span class=cl>  20/20 <span class=o>[==============================]</span> - 0s 13ms/step - loss: 1.7398 - sparse_categorical_crossentropy: 1.7248
</span></span><span class=line><span class=cl>  Epoch 5/5
</span></span><span class=line><span class=cl>  20/20 <span class=o>[==============================]</span> - 0s 13ms/step - loss: 1.5818 - sparse_categorical_crossentropy: 1.5736
</span></span></code></pre></div><p>With our TensorBoard <code>callback</code> in place, the model&rsquo;s <code>fit</code> method will generate the standard summaries that TB can conveniently visualize.</p><p>If you haven&rsquo;t run the code below, an already generated graph is <a href=generated/images/tech/custom.pdf>here</a>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#%load_ext tensorboard</span>
</span></span><span class=line><span class=cl><span class=c1>#%tensorboard --logdir /tmp/q/logs</span>
</span></span></code></pre></div><p>We can also switch over to the new <code>eager</code> execution mode.</p><p>Once again, this is particularly convenient for experimentation, as all ops are immediately executed. And here is a much shortened <code>eager</code> session.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># import ragged as qr</span>
</span></span><span class=line><span class=cl><span class=c1># qr.main_eager(ps, dset_for(ps), model_for(ps))</span>
</span></span></code></pre></div><p>This concludes our blog, please see how to use the <code>autograph</code> features with our model by clicking on the next blog.</p></div></main></div><footer class="qal-footer py-5 bg-light"><div class=container><div class=row><div class=col-lg><a class=d-inline-flex href=../../><svg xmlns="http://www.w3.org/2000/svg" width="40" height="32" class="d-block me-2" viewBox="0 0 118 94" role="img"><title>Silcrow</title><path d="m67.476567 58.848956q2.916668 2.114585 4.375002 4.812503t1.458334 5.942711q0 5.250002-4.520836 8.421879-4.520835 3.208335-10.60938 3.208335-5.541669.0-9.406254-2.552085-3.864586-2.552084-3.864586-6.270836.0-2.151043 1.421876-3.500002 1.421876-1.3125 3.208335-1.3125 1.932293.0 3.026043 1.09375 1.093751 1.130209 1.786459 3.609377.911459 3.09896 2.296876 3.97396 1.385418.911459 3.208335.911459 2.187501.0 3.75521-1.239584t1.567709-3.026043q0-1.458334-1.020833-3.135418-1.057293-1.640626-6.708337-5.468753-6.526045-4.375002-9.369796-6.781253-2.843751-2.44271-4.375002-5.322919-1.531251-2.916669-1.531251-6.19792.0-3.09896 1.348959-5.432294 1.385417-2.333335 3.208335-3.427085 1.822918-1.130209 4.302085-1.713543-3.098959-2.260418-4.666668-4.921877-1.56771-2.66146-1.56771-5.76042.0-5.322919 4.484378-8.640629 4.484377-3.354168 10.901046-3.354168 5.395836.0 9.333338 2.515626t3.937502 6.088545q0 2.114584-1.494792 3.463543-1.494793 1.348959-3.427085 1.348959-1.895834.0-2.843752-.984375-.947917-1.020834-1.859376-3.718752-.838542-2.552085-2.078125-3.609377-1.239584-1.057292-3.463544-1.057292-2.296876.0-3.937502 1.276042-1.604167 1.276043-1.604167 3.062502.0 2.041667 1.567709 3.682293 1.531251 1.640626 7.473962 5.432294 5.578128 3.572919 8.239587 5.76042 2.697918 2.151043 4.229169 5.140627 1.567709 2.989585 1.567709 6.453128.0 4.411461-2.078126 7.218754-2.078126 2.807293-6.270836 4.010418zm1.166667-7.000003q0-3.682293-6.234378-8.531254-6.19792-4.885419-9.187505-4.885419-1.385417.0-2.661459 1.09375-1.239584 1.057293-1.239584 2.515627.0 3.463543 6.307295 8.421879 6.343753 4.958335 9.260421 4.958335 1.53125.0 2.625001-1.057292 1.130209-1.057292 1.130209-2.515626z" fill="#0"/></svg><span class=fs-5>&copy; 2022 Qnarre</span></a><ul class="list-unstyled small text-muted"><li class=mb-2>Software is our passion.</li></ul></div></div></div></footer><script src=../../js/bootstrap.bundle.min.js></script>
<script src=../../js/script.min.js></script></body></html>